{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 3 Reconocimiento de Formas: Clasificador Estadístico Bayesiano\n",
    "\n",
    "* **Alumno 1**: Javier Barragán Haro\n",
    "* **Alumno 2**: Victor Nieves Sanchez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "\n",
    "class ClassifBayesiano(Classifier):\n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase\"\"\"\n",
    "        self.labels = labels\n",
    "        self.ln_apriories = None\n",
    "        self.means = None\n",
    "        self.ln_determinants = None\n",
    "        self.inv_covs = None\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador. Dado que es un clasificador Gausiano Bayesiano, \n",
    "        se aprenderán los parámetros de las gausianas de cada clase.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una característica\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        \n",
    "        y = pd.factorize(y)[0]\n",
    "        \n",
    "        # Contar cuantos ejemplos hay de cada etiqueta\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Usando el contador de ejemplos de cada etiqueta, calcular el logaritmo neperiano de las probabilidades a-priori\n",
    "        self.ln_apriories = np.array([np.log((counts[i]/np.sum(counts))) for i in unique])\n",
    "        \n",
    "        # Calcular para los ejemplos de cada clase, la media de cada una de sus características (centroide)\n",
    "        self.means = np.array([np.mean(X[y==i], axis=0) for i in unique])\n",
    "        \n",
    "        # Sustraer a los ejemplos de cada clase su media y calcular su matriz de covarianzas (puedes emplear compresión de listas) \n",
    "        covs = np.array([np.cov(X[y==i] - self.means[i], rowvar=False) for i in unique])\n",
    "\n",
    "        # Para cada una de las clases, calcular el logaritmo neperiano de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.ln_determinants = np.log(list(map(np.linalg.det, covs)))\n",
    "        \n",
    "        # Para cada una de las clases, calcular la inversa de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.inv_covs = np.array(list(map(np.linalg.pinv,covs)))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\" \n",
    "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
    "\n",
    "        # Resta la media de cada clase a cada ejemplo en X\n",
    "        X_mean0 = self.means[:,np.newaxis,:] - X\n",
    "        \n",
    "        # Calcula el logaritmo de la función de decisión gausiana \n",
    "        # Transparencias de Métodos paramétricos de clasificación: página 14:\n",
    "        # -(1/2)ln|Sigma_i| - (1/2)*(x- mu_i)^T Sigma_i^-1 (x- mu_i) + lnP(alpha_i)\n",
    "        return -0.5 * self.ln_determinants[:, np.newaxis] \\\n",
    "            - 0.5 * np.array([np.sum((X_mean0[i] @ self.inv_covs[i]) \n",
    "                                     * X_mean0[i], axis=1) for i in np.unique(y)]) \\\n",
    "            + self.ln_apriories[:, np.newaxis]\n",
    "\n",
    "        \n",
    "    def pred_label(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(X, axis = 0)\n",
    "    \n",
    "    def num_aciertos(self, X): \n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(X[i] == self.labels[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "\n",
    "        return number, (number / len(X)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jry9Y_njWsg6"
   },
   "source": [
    "## Iris Dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "outputId": "64d62704-bc9c-4914-c69d-ed4ce1dc0e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 147 / 150\n",
      "Success rate: 98.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRs9Za2BLzE_"
   },
   "source": [
    "## Wine dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "dbakRtC79fqA",
    "outputId": "ad5ece9a-5dde-4d72-d6f1-36f4cab44dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 177 / 178\n",
      "Success rate: 99.43820224719101\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CJ0q3hQL2Ev"
   },
   "source": [
    "## Breast cancer dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Breast cancer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "id": "_54KE327_QEa",
    "outputId": "ca6814c6-3e0a-49fc-962e-e6df04622303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 554 / 569\n",
      "Success rate: 97.36379613356766\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4GoC5IsK_J2"
   },
   "source": [
    "## MNIST Database (Modified National Institute of Standards and Technology database)\n",
    "MNIST es una base de datos de texto manuscrito, que se usa de forma clásica para entrenar sistemas de procesado de imágenes.\n",
    "\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "tv18S4OWLDGr",
    "outputId": "b08c0904-0a2e-49bb-a197-c9eff303f097"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 5421 / 60000\n",
      "Success rate: 9.035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1lZU4KULWCL"
   },
   "source": [
    "## Isolet Dataset (Isolated Letter Speech Recognition)\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Isolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "KWsJbsoRLc9P",
    "outputId": "fd69bfb9-5ed4-475c-bac0-0fa209a60f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[-0.4394 -0.093   0.1718 ...  0.641   0.5898 -0.4872]\n",
      " [-0.4348 -0.1198  0.2474 ...  0.4318  0.4546 -0.091 ]\n",
      " [-0.233   0.2124  0.5014 ...  0.254   0.1588 -0.4762]\n",
      " ...\n",
      " [-0.6696 -0.373   0.1584 ...  0.0728  0.0728 -0.5818]\n",
      " [-0.5764 -0.1764  0.5106 ...  0.3044 -0.0434 -0.5   ]\n",
      " [-0.6624 -0.3334  0.3666 ... -0.0894 -0.1708 -0.317 ]]\n",
      "y: \n",
      "[ 0  0  1 ... 24 25 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 300 / 7797\n",
      "Success rate: 3.8476337052712584\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "print(\"X: \\n\" + str(X))\n",
    "print(\"y: \\n\" + str(y))\n",
    "\n",
    "# Nota: Si la matriz de covarianzas no tiene rango completo, no podrás invertirlas, \n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_kQ7OJd9fqD"
   },
   "source": [
    "## Resultados\n",
    "Resultados de los tres experimentos:\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147 | 98.00 |\n",
    "| Wine   | 177 | 99.43 |\n",
    "| Cancer | 554 | 97.36 |\n",
    "| MNIST  | 5421 / 60000 | 9.03 |\n",
    "| Isolet | 300 / 7797 | 3.85 |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
