{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Final Reconocimiento de Formas\n",
    "\n",
    "* **Alumno 1**: Javier Barragán Haro\n",
    "* **Alumno 2**: Victor Nieves Sanchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "En esta práctica se pretende explicar lo aprendido hasta este momento en la asignatura de Reconocimiento de Formas.\n",
    "<br>\n",
    "Principalmente nos centraremos en la construcción de dos clasificadores (distancia euclídea y estadístico bayesiano), en su regularización, en la evaluación del rendimiento y por último, se enseñará una aplicación real de un OCR (_Reconocimiento Óptico de Caracteres_).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clasificador de la distancia euclídea\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "Primero vamos a explicar qué se entiende por **distancia euclídea** o **euclidiana**. Es la distancia “ordinaria” entre dos puntos de un espacio eucídeo. La distancia se deduce a partír del teorema de Pitágoras.\n",
    "<br>\n",
    "En general, la distancia euclidiana entre los puntos $P=(p_1,p_2,...,p_n)$ y $Q=(q_1,q_2,...,q_n)$ del espacio euclídeo n-dimensional, se define como:\n",
    "<div style=\"text-align: center\">\n",
    "$d_E(P,Q) = \\sqrt{(p_2-q_1)^2+(p_2-q_1)^2 + ... + (p_n-q_n)^2}=\\sum_{i=1}^{n}{(p_i-q_i)^2}$\n",
    "</div>\n",
    "<h3> Hipótesis </h3>\n",
    "<li> La dispersión de las clases es pequeña en relación a la distancia entre ellas. Es decir, $d \\gg \\sigma$\n",
    "![i1.png](images/i1.png)</li>\n",
    "<li> El centroide, $z_i$ es el representante de la clase\n",
    "<div style=\"text-align: center\">\n",
    "    $z_i=\\frac{1}{card(\\alpha_i)}\\sum_{\\forall{x\\in{\\alpha_i}}}{x}$\n",
    "    ![i2.png](images/i2.png)</li>\n",
    "</div>\n",
    "<h3> Fundamentos </h3>\n",
    "<li> Se asocia a cada clase una función de pertenencia $f_i(x)=d_E(x,z_i)$\n",
    "![i3.png](images/i3.png)</li>\n",
    "<li> Se clasifica un objeto $x$ en la clase cuyo representante sea el más cercano $x \\in \\alpha_i$ tal que $i=argmin_j\\{f_i(x)\\}$</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código del clasificador euclídeo\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ClassifEuclid(Classifier):\n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase\"\"\"\n",
    "        self.labels = labels\n",
    "        self.centroids = []\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        self.centroids = np.array([np.mean(x[y==i], axis=0) for i in np.unique(y)])\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.linalg.norm(self.centroids[:, np.newaxis] - x, axis=2)\n",
    "\n",
    "    def pred_label(self, x):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmin(x,axis=0)\n",
    "\n",
    "    def num_aciertos(self, x, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(x[i] == y[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "        return number, (number / len(x)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Database\n",
      "Correct answers: 48479 / 60000\n",
      "Success rate: 80.79833333333333\n"
     ]
    }
   ],
   "source": [
    "# ------ MNIST Database ------\n",
    "from sklearn.datasets import fetch_openml\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000].astype(int)\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(y)\n",
    "classifEuclid.fit(X, y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, list(y))\n",
    "print(\"MNIST Database\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolet Database\n",
      "Correct answers: 6843 / 7797\n",
      "Success rate: 87.7645248172374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ------ Isolet Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(y)\n",
    "classifEuclid.fit(X, y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, y)\n",
    "print(\"Isolet Database\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Database\n",
      "Correct answers: 139 / 150\n",
      "Success rate: 92.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# --------- Iris database ---------\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_iris()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "print(\"Iris Database\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Database\n",
      "Correct answers: 129 / 178\n",
      "Success rate: 72.47191011235955\n"
     ]
    }
   ],
   "source": [
    "# --------- Wine database ---------\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_wine()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "print(\"Wine Database\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer Database\n",
      "Correct answers: 507 / 569\n",
      "Success rate: 89.103690685413\n"
     ]
    }
   ],
   "source": [
    "# --------- Cancer database ---------\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_breast_cancer()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "print(\"Cancer Database\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de resultados:\n",
    "\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos (%) |\n",
    "| --- | --- | --- |\n",
    "| Iris   |  139 / 150 | 92.66 |\n",
    "| Wine   | 129/178 | 72.47  |\n",
    "| Cancer | 507/569 | 89.10 |\n",
    "| MNIST  | 48479 / 60000 |80.80|\n",
    "| Isolet | 6843 / 7797 | 87.76 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clasificador Estadístico Bayesiano\n",
    "<div style=\"text-align: justify\">\n",
    "El clasificador de la distancia euclídea falla cuando no se cumple la hipótesis sobre la distribución de muestras.\n",
    "![i4.png](images/i4.png)\n",
    "El **clasificador estadístico bayesiano** es el clasificador que minimiza la probabilidad de error.\n",
    "<br>\n",
    "El criterio de clasificación que minimiza la probabilidad de error asigna a un objeto a aquella clase cuya probabilidad a posteriori sea máxima.\n",
    "<div style=\"text-align: center\">\n",
    "$f_i(x)=P(\\alpha_i\\mid x)= p(x\\mid \\alpha_i)*P(\\alpha_i)$\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código del clasificador estadístico bayesiano\n",
    "class ClassifBayesiano(Classifier):\n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase\"\"\"\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.ln_apriories = None\n",
    "        self.means = None\n",
    "        self.ln_determinants = None\n",
    "        self.inv_covs = None\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador. Dado que es un clasificador Gausiano Bayesiano, \n",
    "        se aprenderán los parámetros de las gausianas de cada clase.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una característica\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        \n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        \n",
    "        y = pd.factorize(y)[0]\n",
    "        \n",
    "        # Contar cuantos ejemplos hay de cada etiqueta\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Usando el contador de ejemplos de cada etiqueta, calcular el logaritmo neperiano de las probabilidades a-priori\n",
    "        self.ln_apriories = np.array([np.log((counts[i]/np.sum(counts))) for i in unique])\n",
    "        \n",
    "        # Calcular para los ejemplos de cada clase, la media de cada una de sus características (centroide)\n",
    "        self.means = np.array([np.mean(X[y==i], axis=0) for i in unique])\n",
    "        \n",
    "        # Sustraer a los ejemplos de cada clase su media y calcular su matriz de covarianzas (puedes emplear compresión de listas) \n",
    "        covs = np.array([np.cov(X[y==i] - self.means[i], rowvar=False) for i in unique])\n",
    "\n",
    "        # Para cada una de las clases, calcular el logaritmo neperiano de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.ln_determinants = np.log(list(map(np.linalg.det, covs)))\n",
    "        \n",
    "        # Para cada una de las clases, calcular la inversa de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.inv_covs = np.array(list(map(np.linalg.pinv,covs)))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\" \n",
    "        \n",
    "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
    "\n",
    "        # Resta la media de cada clase a cada ejemplo en X\n",
    "        X_mean0 = self.means[:,np.newaxis,:] - X\n",
    "        \n",
    "        # Calcula el logaritmo de la función de decisión gausiana \n",
    "        return -0.5 * self.ln_determinants[:, np.newaxis] \\\n",
    "            - 0.5 * np.array([np.sum((X_mean0[i] @ self.inv_covs[i]) \n",
    "                                     * X_mean0[i], axis=1) for i in np.unique(y)]) \\\n",
    "            + self.ln_apriories[:, np.newaxis]\n",
    "        \n",
    "    def pred_label(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(X, axis = 0)\n",
    "    \n",
    "    def num_aciertos(self, X): \n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(X[i] == self.labels[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "        return number, (number / len(X)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset\n",
      "Correct answers: 147 / 150\n",
      "Success rate: 98.0\n"
     ]
    }
   ],
   "source": [
    "# ------ Iris Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Iris Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset\n",
      "Correct answers: 177 / 178\n",
      "Success rate: 99.43820224719101\n"
     ]
    }
   ],
   "source": [
    "# ------ Wine Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Wine Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer Dataset\n",
      "Correct answers: 554 / 569\n",
      "Success rate: 97.36379613356766\n"
     ]
    }
   ],
   "source": [
    "# ------ Cancer Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Cancer Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset\n",
      "Correct answers: 5421 / 60000\n",
      "Success rate: 9.035\n"
     ]
    }
   ],
   "source": [
    "# ------ MNIST Database ------\n",
    "# 1. Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"MNIST Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolet Dataset\n",
      "Correct answers: 300 / 7797\n",
      "Success rate: 3.8476337052712584\n"
     ]
    }
   ],
   "source": [
    "# ------ Isolet Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "#print(\"X: \\n\" + str(X))\n",
    "#print(\"y: \\n\" + str(y))\n",
    "\n",
    "# Nota: Si la matriz de covarianzas no tiene rango completo, no podrás invertirlas, \n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesiano(y)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Isolet Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de resultados obtenidos:\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147 | 98.00 |\n",
    "| Wine   | 177 | 99.43 |\n",
    "| Cancer | 554 | 97.36 |\n",
    "| MNIST  | 5421 / 60000 | 9.03 |\n",
    "| Isolet | 300 / 7797 | 3.85 |\n",
    "\n",
    "\n",
    "<div style=\"text-align: justify\">\n",
    "Vemos claramente una mejora en las bases de datos Iris, Wine y Cancer, pero en las otras dos (MNIST e Isolet) no, ya que el clasificador implementado no es capaz de clasificar todos los datos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regularización\n",
    "La regularización se utiliza para apoyar diseños de clasificación que cuentan con pocas muestras o con muestras que estan desbalanceadas. Esto se consigue con un preprocesamiento de los datos, para eliminar datos redundantes o que favorezcan mayoritariamente una de las clases en detrimiento de las demas.\n",
    "\n",
    "### Clasificador Estadístico Bayesiano paramétrico\n",
    "El clasificador Estadístico Bayesiano Paramétrico entiende que los datos pertenencen a distintas clases y que las muestras del Universo de Trabajo son idenpendientes y estan identicamente distribuidas. Partiendo de esto se define una matriz con las varianzas y las covarianzas de los elementos del UT, que representan la posición y la orientación de la distribución. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código del clasificador estadístico bayesiano paramétrico\n",
    "from sklearn.covariance import ShrunkCovariance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class ClassifBayesianoParametrico(Classifier):\n",
    "    def __init__(self, share_covs=False, shrinkage=0.0):\n",
    "        \"\"\"Constructor de la clase\n",
    "        share_covs: Indica si la matriz de covarianzas va a ser compartida entre las distintas clases.\n",
    "        shrinkage: Parámetro que determina la diagonalidad de la matriz de covarianzas. Ver sklearn.covariance.ShrunkCovariance\n",
    "        \"\"\"\n",
    "        assert 0 <= shrinkage <= 1\n",
    "        self.labels = None\n",
    "        self.ln_apriories = None\n",
    "        self.means = None\n",
    "        self.ln_determinants = None\n",
    "        self.inv_covs = None\n",
    "        self.share_covs = share_covs\n",
    "        self.shrinkage = shrinkage\n",
    "        self.scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        self.labels = y\n",
    "        # Aseguramos que las etiquetas son numeros tal que: [0, 1, ..., N]\n",
    "        y = pd.factorize(y)[0]\n",
    "\n",
    "        # Preprocesamos los datos de entrada\n",
    "        X = self.scaler.fit_transform(X)       \n",
    "\n",
    "        # Contar cuantos ejemplos hay de cada etiqueta\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # Usando el contador de ejemplos de cada etiqueta, calcular el logaritmo neperiano de las probabilidades a-priori\n",
    "        self.ln_apriories = np.array([np.log((counts[i]/np.sum(counts))) for i in unique])\n",
    "        \n",
    "        # Calcular para los ejemplos de cada clase, la media de cada una de sus características (centroide)\n",
    "        self.means = np.array([np.mean(X[y==i], axis=0) for i in unique])\n",
    "        \n",
    "        if self.share_covs:\n",
    "            # Restamos al dato de cada clase su centroide\n",
    "            X_mean = np.array([])\n",
    "            for i in unique:\n",
    "                X_mean = np.append(X_mean.reshape(-1, X.shape[1]), X[y==i] - self.means[i], axis=0)\n",
    "\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            cov = ShrunkCovariance(shrinkage=self.shrinkage).fit(X_mean).covariance_\n",
    "\n",
    "            # La reproducimos tantas veces como número de clases\n",
    "            covs = np.tile(cov, (len(unique), 1, 1))\n",
    "         \n",
    "        else:\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            covs = np.array([ShrunkCovariance(shrinkage=self.shrinkage).fit(X[y==i]).covariance_ for i in unique])\n",
    "\n",
    "        # Para cada una de las clases, calcular el logaritmo neperiano de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.ln_determinants = np.log(list(map(np.linalg.det, covs)))\n",
    "       \n",
    "        # Para cada una de las clases, calcular la inversa de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.inv_covs = list(map(np.linalg.inv, covs))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        \n",
    "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
    "\n",
    "        # Preprocesamos nuestros datos\n",
    "        X = self.scaler.fit_transform(X)        \n",
    "\n",
    "        # Resta la media de cada clase a cada ejemplo en X\n",
    "        new_X = self.means[:,np.newaxis,:] - X \n",
    "        \n",
    "        # Calcula el logaritmo de la función de decisión gausiana\n",
    "        return -0.5 * self.ln_determinants[:, np.newaxis] \\\n",
    "            - 0.5 * np.array([np.sum((new_X[i] @ self.inv_covs[i]) \n",
    "                                     * new_X[i], axis=1) for i in np.unique(y)]) \\\n",
    "            + self.ln_apriories[:, np.newaxis]\n",
    "    \n",
    "    def pred_label(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(X, axis = 0)\n",
    "    \n",
    "    def num_aciertos(self, X): \n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(X[i] == self.labels[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "        return number, (number / len(X)) * 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset\n",
      "Correct answers: 147 / 150\n",
      "Success rate: 98.0\n"
     ]
    }
   ],
   "source": [
    "# ------ Iris Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayesP = ClassifBayesianoParametrico()\n",
    "ClassifBayesP.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayesP.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayesP.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayesP.num_aciertos(labels_matrix)\n",
    "print(\"Iris Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset\n",
      "Correct answers: 177 / 178\n",
      "Success rate: 99.43820224719101\n"
     ]
    }
   ],
   "source": [
    "# ------ Wine Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayesP = ClassifBayesianoParametrico()\n",
    "ClassifBayesP.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayesP.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayesP.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayesP.num_aciertos(labels_matrix)\n",
    "print(\"Wine Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer Dataset\n",
      "Correct answers: 555 / 569\n",
      "Success rate: 97.53954305799648\n"
     ]
    }
   ],
   "source": [
    "# ------ Cancer Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayesP = ClassifBayesianoParametrico()\n",
    "ClassifBayesP.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayesP.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayesP.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayesP.num_aciertos(labels_matrix)\n",
    "print(\"Cancer Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset\n",
      "Correct answers: 52289 / 60000\n",
      "Success rate: 87.14833333333334\n"
     ]
    }
   ],
   "source": [
    "# ------ MNIST Database ------\n",
    "# 1. Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayesP = ClassifBayesianoParametrico(share_covs=True, shrinkage=0.3)\n",
    "ClassifBayesP.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayesP.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayesP.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayesP.num_aciertos(labels_matrix)\n",
    "print(\"MNIST Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolet Dataset\n",
      "Correct answers: 7489 / 7797\n",
      "Success rate: 96.04976272925484\n"
     ]
    }
   ],
   "source": [
    "# ------ Isolet Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayesP = ClassifBayesianoParametrico(share_covs=True, shrinkage=0.26) \n",
    "ClassifBayesP.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayesP.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayesP.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayesP.num_aciertos(labels_matrix)\n",
    "print(\"Isolet Dataset\")\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de resultados:\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   |  147 / 150|98.00|\n",
    "| Wine   | 177 / 178|99.44 | \n",
    "| Cancer | 555 / 569|97.54 |\n",
    "| MNIST  | 52287 / 60000|87.15 |\n",
    "| Isolet | 7489 / 7797 |  96.05 |\n",
    "\n",
    "<div style=\"text-align: justify\">\n",
    "Como se puede observar, se han mejorado los resultados de todas las bases de datos respecto a las soluciones obtenidas con el clasificador de la distancia euclídea.\n",
    "<br>\n",
    "Esta mejora es debida a que el clasificador de la distancia euclídea no modela la distribución de las muestras en cada clase. Además, los datos que tienen mayor dispersión, no son clasificados correctamente (falla la hipótesis determinista).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluación del Rendimiento\n",
    "**Nota**: Se ha cambiado la implementación del Clasificador Bayesiano paramétrico para poder evaluar mejor el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "class ClassifBayesianoParametrico(Classifier):\n",
    "    def __init__(self, share_covs=False, shrinkage=0.0):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase\"\"\"\n",
    "        assert 0 <= shrinkage <= 1\n",
    "        self.labels = None\n",
    "        self.ln_apriories = None\n",
    "        self.means = None\n",
    "        self.ln_determinants = None\n",
    "        self.inv_covs = None\n",
    "        self.share_covs = share_covs\n",
    "        self.shrinkage = shrinkage\n",
    "        self.scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        assert np.max(y) < len(np.unique(y)), \"Error: Las etiquetas deben ser enteros entre 0 y el número de clases.\\n\" \\\n",
    "                                              \"Puedes hacer esto empleando:\\ny = pd.factorize(y)[0]\"\n",
    "        # Entrena el clasificador\n",
    "\n",
    "        # Preprocesamos los datos de entrada\n",
    "        X = self.scaler.fit_transform(X)       \n",
    "\n",
    "        # Contar cuantos ejemplos hay de cada etiqueta\n",
    "        self.labels, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        # Usando el contador de ejemplos de cada etiqueta, calcular el logaritmo neperiano de las probabilidades a-priori\n",
    "        self.ln_apriories = np.array([np.log((counts[i]/np.sum(counts))) for i in self.labels])\n",
    "\n",
    "        # Calcular para los ejemplos de cada clase, la media de cada una de sus características (centroide)\n",
    "        self.means = np.array([np.mean(X[y==i], axis=0) for i in self.labels])\n",
    "        \n",
    "        if self.share_covs:\n",
    "            # Restamos al dato de cada clase su centroide\n",
    "            X_mean = np.array([])\n",
    "            for i in self.labels:\n",
    "                X_mean = np.append(X_mean.reshape(-1, X.shape[1]), X[y==i] - self.means[i], axis=0)\n",
    "\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            cov = ShrunkCovariance(shrinkage=self.shrinkage).fit(X_mean).covariance_\n",
    "\n",
    "            # La reproducimos tantas veces como número de clases\n",
    "            covs = np.tile(cov, (len(self.labels), 1, 1))\n",
    "         \n",
    "        else:\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            covs = np.array([ShrunkCovariance(shrinkage=self.shrinkage).fit(X[y==i]).covariance_ for i in self.labels])\n",
    "\n",
    "        # Para cada una de las clases, calcular el logaritmo neperiano de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.ln_determinants = np.log(list(map(lambda x: np.linalg.det(x), covs)))\n",
    "\n",
    "        # Para cada una de las clases, calcular la inversa de su matriz de covarianzas (puedes emplear compresión de listas o la función map)\n",
    "        self.inv_covs = np.array(list(map(lambda x: np.linalg.pinv(x), covs)))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
    "        \n",
    "        # Calcula y devuelve la probabilidad de cada clase\n",
    "        \n",
    "        # Preprocesamos nuestros datos\n",
    "        X = self.scaler.fit_transform(X)        \n",
    "\n",
    "        # Resta la media de cada clase a cada ejemplo en X  \n",
    "        X_mean0 = np.array(X[:, np.newaxis] - self.means)\n",
    "\n",
    "        # Calcula el logaritmo de la función de decisión gausiana\n",
    "        # -(1/2)ln|Sigma_i| - (1/2)*(x- mu_i)^T Sigma_i^-1 (x- mu_i) + lnP(alpha_i)\n",
    "        grado_de_pertenencia = np.array(list(map(lambda x: -(1/2)*(self.ln_determinants \n",
    "                   + np.matmul(np.matmul(x.reshape(len(self.labels),1,X.shape[1]),self.inv_covs), \n",
    "                   x.reshape(len(self.labels),1,X.shape[1]).transpose(0,2,1)).reshape(len(self.labels)))\n",
    "                   + self.ln_apriories, X_mean0)))\n",
    "\n",
    "        return grado_de_pertenencia\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Calcula y devuelve la clase más probable\n",
    "        return self.labels[np.argmax(self.predict_proba(X), axis=1)]\n",
    "\n",
    "    def  num_aciertos(self,X,y):\n",
    "        estimation = self.predict(X)\n",
    "        aciertos = (estimation == y).sum()\n",
    "        return aciertos, aciertos/len(y) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "def best_shrinkage_clf(X, y, k, shrinkages, share_covs):\n",
    "    \"\"\"\n",
    "    Busca el clasificador bayesiano regularizado con el mejor shrinkage. \n",
    "    :param X: Ejemplos de la dase de datos\n",
    "    :param y: Etiquetas de los ejemplos\n",
    "    :param k: Número de divisiones en la validación cruzada (k-fold)\n",
    "    :param shrinkages: Lista de posibles shrinkages que conforman la rejilla de búsqueda\n",
    "    :param share_covs: Lista de posibles valores para share_covs que conforman la rejilla de búsqueda\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    cbp = ClassifBayesianoParametrico()\n",
    "    params = {'shrinkage': shrinkages, 'share_covs': share_covs}\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-2, scoring='accuracy', cv=k).fit(X, y)\n",
    "    best_clf = clf.best_estimator_\n",
    "    # print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "    print(\"\\tSelected shrinkage = {}, share_covs = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\\n\".format(best_clf.shrinkage,\n",
    "                                                   best_clf.share_covs,\n",
    "                                                   result_score_mean,\n",
    "                                                   result_score_std))\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset\n",
      "\u001b[1m Clasificador Euclídeo \u001b[0m \n",
      "\n",
      "Accuracy: 0.97 (+/- 0.04) \n",
      "\n",
      "Matriz de confusión con clasificador de la distancia euclidea: \n",
      " [[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  0 50]] \n",
      "\n",
      "\u001b[1m Clasificador Estadístico Paramétrico \u001b[0m \n",
      "\n",
      "\tSelected shrinkage = 0.1, share_covs = True\n",
      "\tAccuracy: 0.953 (+/- 0.034)\n",
      "\n",
      "Accuracy: 0.95 (+/- 0.07) \n",
      "\n",
      "Matriz de confusión con clasificador bayesiano parametrico: \n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  1 49]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Iris Database ------\n",
    "import sklearn\n",
    "from time import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = pd.factorize(dataset.target)[0]\n",
    "\n",
    "\n",
    "# 2. Baraja los datos para hacer validación cruzada\n",
    "X, y = sklearn.utils.shuffle(X, y)\n",
    "\n",
    "# Evaluar el clasificador de la distancia eucídea usando cross validation (k-fold=5)\n",
    "k = 5\n",
    "print(\"Iris Dataset\")\n",
    "print(\"\\033[1m\", \"Clasificador Euclídeo\", \"\\033[0m\", \"\\n\")\n",
    "cde = SVC(kernel='linear', C=1).fit(X,y)\n",
    "scoresCde = cross_val_score(cde, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCde.mean(), scoresCde.std() * 2), \"\\n\")\n",
    "mConfusionCde = confusion_matrix(y, cde.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador de la distancia euclidea: \\n\", mConfusionCde, \"\\n\")\n",
    "\n",
    "# Haz una selección de modelos para buscar shrinkage del clasificador \n",
    "# estadístico paramétrico que obtiene el mejor accuracy. Usa para ello cross validation (k-fold=5)\n",
    "print(\"\\033[1m\", \"Clasificador Estadístico Paramétrico\", \"\\033[0m\", \"\\n\")\n",
    "\n",
    "clf = best_shrinkage_clf(X, y, k, [1.0, 0.8, 0.6, 0.5, 0.4, 0.2, 0.1, 0.0], [True, False])\n",
    "cbp = ClassifBayesianoParametrico(clf.share_covs, clf.shrinkage).fit(X,y)\n",
    "scoresCbp = cross_val_score(cbp, X, y, scoring='accuracy', cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCbp.mean(), scoresCbp.std() * 2), \"\\n\")\n",
    "\n",
    "mConfusionCbp = confusion_matrix(y, cbp.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador bayesiano parametrico: \\n\", mConfusionCbp, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Dataset\n",
      "\u001b[1m Clasificador Euclídeo \u001b[0m \n",
      "\n",
      "Accuracy: 0.94 (+/- 0.10) \n",
      "\n",
      "Matriz de confusión con clasificador de la distancia euclidea: \n",
      " [[59  0  0]\n",
      " [ 0 70  1]\n",
      " [ 0  0 48]] \n",
      "\n",
      "\u001b[1m Clasificador Estadístico Paramétrico \u001b[0m \n",
      "\n",
      "\tSelected shrinkage = 0.2, share_covs = False\n",
      "\tAccuracy: 0.972 (+/- 0.018)\n",
      "\n",
      "Accuracy: 0.97 (+/- 0.04) \n",
      "\n",
      "Matriz de confusión con clasificador bayesiano parametrico: \n",
      " [[59  0  0]\n",
      " [ 0 71  0]\n",
      " [ 0  0 48]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ------ Wine Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = pd.factorize(dataset.target)[0]\n",
    "\n",
    "# 2. Baraja los datos para hacer validación cruzada\n",
    "X, y = sklearn.utils.shuffle(X, y)\n",
    "\n",
    "# Evaluar el clasificador de la distancia eucídea usando cross validation (k-fold=5)\n",
    "k = 5\n",
    "print(\"Wine Dataset\")\n",
    "print(\"\\033[1m\", \"Clasificador Euclídeo\", \"\\033[0m\", \"\\n\")\n",
    "cde = SVC(kernel='linear', C=1).fit(X,y)\n",
    "scoresCde = cross_val_score(cde, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCde.mean(), scoresCde.std() * 2), \"\\n\")\n",
    "mConfusionCde = confusion_matrix(y, cde.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador de la distancia euclidea: \\n\", mConfusionCde, \"\\n\")\n",
    "\n",
    "# Haz una selección de modelos para buscar shrinkage del clasificador \n",
    "# estadístico paramétrico que obtiene el mejor accuracy. Usa para ello cross validation (k-fold=5)\n",
    "print(\"\\033[1m\", \"Clasificador Estadístico Paramétrico\", \"\\033[0m\", \"\\n\")\n",
    "\n",
    "clf = best_shrinkage_clf(X, y, k, [1.0, 0.8, 0.6, 0.5, 0.4, 0.2, 0.1, 0.0], [True, False])\n",
    "cbp = ClassifBayesianoParametrico(clf.share_covs, clf.shrinkage).fit(X,y)\n",
    "scoresCbp = cross_val_score(cbp, X, y, scoring='accuracy', cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCbp.mean(), scoresCbp.std() * 2), \"\\n\")\n",
    "mConfusionCbp = confusion_matrix(y, cbp.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador bayesiano parametrico: \\n\", mConfusionCbp, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancer Dataset\n",
      "\u001b[1m Clasificador Euclídeo \u001b[0m \n",
      "\n",
      "Accuracy: 0.95 (+/- 0.03) \n",
      "\n",
      "Matriz de confusión con clasificador de la distancia euclidea: \n",
      " [[201  11]\n",
      " [  8 349]] \n",
      "\n",
      "\u001b[1m Clasificador Estadístico Paramétrico \u001b[0m \n",
      "\n",
      "\tSelected shrinkage = 0.5, share_covs = True\n",
      "\tAccuracy: 0.956 (+/- 0.025)\n",
      "\n",
      "Accuracy: 0.96 (+/- 0.05) \n",
      "\n",
      "Matriz de confusión con clasificador bayesiano parametrico: \n",
      " [[187  25]\n",
      " [  1 356]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Cancer Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = pd.factorize(dataset.target)[0]\n",
    "\n",
    "# 2. Baraja los datos para hacer validación cruzada\n",
    "X, y = sklearn.utils.shuffle(X, y)\n",
    "\n",
    "# Evaluar el clasificador de la distancia eucídea usando cross validation (k-fold=5)\n",
    "k = 5\n",
    "print(\"Cancer Dataset\")\n",
    "print(\"\\033[1m\", \"Clasificador Euclídeo\", \"\\033[0m\", \"\\n\")\n",
    "cde = SVC(kernel='linear', C=1).fit(X,y)\n",
    "scoresCde = cross_val_score(cde, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCde.mean(), scoresCde.std() * 2), \"\\n\")\n",
    "mConfusionCde = confusion_matrix(y, cde.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador de la distancia euclidea: \\n\", mConfusionCde, \"\\n\")\n",
    "\n",
    "# Haz una selección de modelos para buscar shrinkage del clasificador \n",
    "# estadístico paramétrico que obtiene el mejor accuracy. Usa para ello cross validation (k-fold=5)\n",
    "print(\"\\033[1m\", \"Clasificador Estadístico Paramétrico\", \"\\033[0m\", \"\\n\")\n",
    "\n",
    "clf = best_shrinkage_clf(X, y, k, [1.0, 0.8, 0.6, 0.5, 0.4, 0.2, 0.1, 0.0], [True, False])\n",
    "cbp = ClassifBayesianoParametrico(clf.share_covs, clf.shrinkage).fit(X,y)\n",
    "scoresCbp = cross_val_score(cbp, X, y, scoring='accuracy', cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresCbp.mean(), scoresCbp.std() * 2), \"\\n\")\n",
    "mConfusionCbp = confusion_matrix(y, cbp.predict(X) , labels=np.unique(y))\n",
    "print(\"Matriz de confusión con clasificador bayesiano parametrico: \\n\", mConfusionCbp, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusionSplitter:\n",
    "    \"\"\"Esta clase nos permite usar GridSearchCV con la evaluación por exclusion.\"\"\"\n",
    "    def __init__(self, train_indices, test_indices):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return [(self.train_indices, self.test_indices)]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolet Dataset\n",
      "\u001b[1m Clasificador Euclídeo \u001b[0m \n",
      "\n",
      "Entrenamiento C. distancia euclideo:  (0, 0.0) \n",
      "\n",
      "Test C. distancia euclideo:  (0, 0.0) \n",
      "\n",
      "\u001b[1m Clasificador Estadístico Paramétrico \u001b[0m \n",
      "\n",
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/victor/.local/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srinkage scores:  [0.87019231 0.93349359 0.03846154]\n",
      "\tSelected shrinkage = 0.5 Share covs = True \n",
      "\tAccuracy: 0.933 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# ------ Isolet Database ------\n",
    "import os\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "isolet_dir = 'isolet_subsets'\n",
    "\n",
    "train_indices = np.load(os.path.join(isolet_dir, 'isolet_train.npy'))\n",
    "test_indices = np.load(os.path.join(isolet_dir, 'isolet_test.npy'))\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X_all, y_all = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y_all = pd.factorize(y_all)[0]\n",
    "X_train, y_train = X_all[train_indices], y_all[train_indices]\n",
    "X_test, y_test = X_all[test_indices], y_all[test_indices]\n",
    "# Dado el tamaño de la BD vamos emplear Exclusión como método de evaluación\n",
    "print(\"Isolet Dataset\")\n",
    "\n",
    "print(\"\\033[1m\", \"Clasificador Euclídeo\", \"\\033[0m\", \"\\n\")\n",
    "# 2. Entrena el clasificador de la distancia eucídea empleando X_train e y_train\n",
    "cde = ClassifEuclid()\n",
    "cde.fit(X_train,y_train)\n",
    "\n",
    "# 3. Evalua el rendimiento en la base de datos de entrenamiento (X_train, y_train)\n",
    "scoresCde = cde.num_aciertos(X_train, y_train)\n",
    "print(\"Entrenamiento C. distancia euclideo: \", scoresCde, \"\\n\")\n",
    "\n",
    "# 4. Evalua el rendimiento en la base de datos de test (X_test, y_test)\n",
    "scoresCde = cde.num_aciertos(X_test, y_test)\n",
    "print(\"Test C. distancia euclideo: \", scoresCde, \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\", \"Clasificador Estadístico Paramétrico\", \"\\033[0m\", \"\\n\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Creamos un objeto spliter para dividir la base de datos en Train y test\n",
    "splitter = ExclusionSplitter(np.arange(0, len(X_train)), \n",
    "                             np.arange(len(X_train), len(X_train) + len(X_test)))\n",
    "\n",
    "# Decidimos los parámetros que vamos a pasar a GridSearchCV para hacer la búsqueda en rejilla\n",
    "# NOTA: Ten cuidado! Un gran número de celdas en la rejilla ralentizará la ejecución\n",
    "# Ejemplo de uso: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "params = {'shrinkage': [1.0, 0.5, 0.0], 'share_covs': [True]}\n",
    "\n",
    "# Definimos la búsqueda en rejilla. \n",
    "clf = GridSearchCV(ClassifBayesianoParametrico(), params, scoring='accuracy', cv=splitter, verbose=1)\n",
    "# Ejecutamos la búsqueda\n",
    "clf = clf.fit(X_all, y_all)\n",
    "# Seleccionamos el clasificador que mojores resultados ha obtenido \n",
    "best_clf = clf.best_estimator_\n",
    "# Mostramos los resultados\n",
    "print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "print(\"\\tSelected shrinkage = {} Share covs = {} \\n\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.shrinkage,\n",
    "                                                                                           best_clf.share_covs,\n",
    "                                                                                           result_score_mean,\n",
    "                                                                                           result_score_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset\n",
      "\u001b[1m Clasificador Euclídeo \u001b[0m \n",
      "\n",
      "Entrenamiento C. distancia euclideo:  (0, 0.0) \n",
      "\n",
      "Test C. distancia euclideo:  (0, 0.0) \n",
      "\n",
      "\u001b[1m Clasificador Estadístico Paramétrico \u001b[0m \n",
      "\n",
      "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/victor/.local/lib/python3.7/site-packages/ipykernel_launcher.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srinkage scores:  [0.8086 0.8726 0.098 ]\n",
      "\tSelected shrinkage = 0.5 Share covs = True \n",
      "\tAccuracy: 0.873 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# ------ MNIST Database ------\n",
    "\n",
    "import idx2numpy\n",
    "\n",
    "def load_mnsit_data(mnist_dir='MNIST', training_split=True):\n",
    "    \"\"\"\n",
    "    This function load the MNIST dataset from a disk directory.\n",
    "    :param mnist_dir: The directory where the MNIST Dataset is stored. The directory should contain the sub-directories:\n",
    "        - t10k-images-idx3-ubyte\n",
    "        - t10k-labels-idx1-ubyte\n",
    "        - train-images-idx3-ubyte\n",
    "        - train-labels-idx1-ubyte\n",
    "    :param training_split: True if we want to load the training examples and data, False for testing.\n",
    "    :return: A tuple with the training examples X in the first element and the y labels in the second one.\n",
    "    \"\"\"\n",
    "    assert type(mnist_dir) == str and type(training_split) == bool\n",
    "    assert os.path.isdir(mnist_dir), \"Error: The directory \\\"{}\\\" does not exists.\".format(mnist_dir)\n",
    "    file = os.path.join(mnist_dir, 'train-images-idx3-ubyte' if training_split else 't10k-images-idx3-ubyte', 'data')\n",
    "    X = idx2numpy.convert_from_file(file)\n",
    "    X = X.reshape(X.shape[0], -1).astype(float)\n",
    "    file = os.path.join(mnist_dir, 'train-labels-idx1-ubyte' if training_split else 't10k-labels-idx1-ubyte', 'data')\n",
    "    y = idx2numpy.convert_from_file(file)\n",
    "    return X, y\n",
    "\n",
    "drive_dir = 'mnist'\n",
    "X_train, y_train = load_mnsit_data(drive_dir, training_split=True)\n",
    "X_test, y_test = load_mnsit_data(drive_dir, training_split=False)\n",
    "\n",
    "# X_train, y_train = load_mnsit_data(training_split=True)\n",
    "# X_test, y_test = load_mnsit_data(training_split=False)\n",
    "\n",
    "X_all = np.append(X_train, X_test, axis=0)\n",
    "y_all = np.append(y_train, y_test, axis=0)\n",
    "\n",
    "print(\"MNIST Dataset\")\n",
    "# Dado el tamaño de la BD vamos emplear Exclusión como método de evaluación\n",
    "\n",
    "print(\"\\033[1m\", \"Clasificador Euclídeo\", \"\\033[0m\", \"\\n\")\n",
    "# 2. Entrena el clasificador de la distancia eucídea empleando X_train e y_train\n",
    "cde = ClassifEuclid()\n",
    "cde.fit(X_train,y_train)\n",
    "\n",
    "# 3. Evalua el rendimiento en la base de datos de entrenamiento (X_train, y_train)\n",
    "scoresCde = cde.num_aciertos(X_train, y_train)\n",
    "print(\"Entrenamiento C. distancia euclideo: \", scoresCde, \"\\n\")\n",
    "\n",
    "# 4. Evalua el rendimiento en la base de datos de test (X_test, y_test)\n",
    "scoresCde = cde.num_aciertos(X_test, y_test)\n",
    "print(\"Test C. distancia euclideo: \", scoresCde, \"\\n\")\n",
    "\n",
    "print(\"\\033[1m\", \"Clasificador Estadístico Paramétrico\", \"\\033[0m\", \"\\n\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creamos un objeto spliter para dividir la base de datos en Train y test\n",
    "splitter = ExclusionSplitter(np.arange(0, len(X_train)), \n",
    "                             np.arange(len(X_train), len(X_train) + len(X_test)))\n",
    "\n",
    "# Decidimos los parámetros que vamos a pasar a GridSearchCV para hacer la búsqueda en rejilla\n",
    "# NOTA: Ten cuidado! Un gran número de celdas en la rejilla ralentizará la ejecución\n",
    "# Ejemplo de uso: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "params = {'shrinkage': [1.0, 0.5, 0.0], 'share_covs': [True]}\n",
    "\n",
    "# Definimos la búsqueda en rejilla. \n",
    "clf = GridSearchCV(ClassifBayesianoParametrico(), params, scoring='accuracy', cv=splitter, verbose=1)\n",
    "# Ejecutamos la búsqueda\n",
    "clf = clf.fit(X_all, y_all)\n",
    "# Seleccionamos el clasificador que mojores resultados ha obtenido \n",
    "best_clf = clf.best_estimator_\n",
    "# Mostramos los resultados\n",
    "print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "print(\"\\tSelected shrinkage = {} Share covs = {} \\n\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.shrinkage,\n",
    "                                                                                           best_clf.share_covs,\n",
    "                                                                                           result_score_mean,\n",
    "                                                                                           result_score_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos son:\n",
    "\n",
    "| Base de datos | Accuracy | Desviación Típica |\n",
    "| --- | --- | --- |\n",
    "| Iris   |0.96|0.05|\n",
    "| Wine   | 0.98|0.05|\n",
    "| Cancer |0.95|0.05|\n",
    "| MNIST  | 0.873| 0.0|\n",
    "| Isolet |0.933|0.0|\n",
    "\n",
    "Para conseguir una estimacion mas acertada se podria modificar el atributo de shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aplicación en un caso real de reconocimiento de texto\n",
    "Para mayor comodidad, este apartado estará en un único notebook llamado \"**_6 Aplicacion OCR.ipynb_**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusiones\n",
    "<div style=\"text-align: justify\">\n",
    "\n",
    "En esta entrega final se puede ver la evolución que hemos tenido a lo largo de la asignatura. Lo que hemos aprendido a sido a crear varios clasificadores, ademas de aprender a  evaluar y mejorar el rendimiento de los mismos. También nos ha servido para asentar los conocimientos teóricos aprendidos a lo largo del curso.\n",
    "\n",
    "\n",
    "<h3>Dificultades</h3>\n",
    "Donde más dificultades hemos encontrado han sido en las entregas 5 y 6 (apartados 5 y 6).\n",
    "<br><br>\n",
    "Con el **apartado 5** tuvimos problemas a la hora de procesar la base de datos MINST e ISOLET. Esto es debido a que no hemos sabido arreglar el código para evaluar el rendimiento, ya que como se aprecia en el apartado, nos salen excepciones en el código. \n",
    "<br><br>\n",
    "En el **apartado 6** hemos tenido problemas para alcanzar un porcentaje cercano al 90% de acierto (porcentaje que deseabamos alcanzar). Esto es debido a que no hemos entendido del todo cómo \"jugar\" con el código proporcionado. Aún así, hemos logrado mejorar el porcentaje de partida (69%).\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
