{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Aprendizaje\n",
    "\n",
    "* **Alumno 1**: Javier Barragán Haro\n",
    "* **Alumno 2**: Victor Nieves Sanchez\n",
    "\n",
    "## 1. Introducción\n",
    "En esta practica se pretende enseñar lo aprendido en las semanas finales de la segunda parte de la asignatura. La idea era poder mostrar lo siguiente:\n",
    "- Algoritmo iterativo tipo perceptrón\n",
    "- Ensembles de clasificadores (variante boosting con un perceptrón como reconocedor de base del ensemble)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptrón\n",
    "El perceptrón es un algoritmo bio inspirado desarrollado por Frank Rosenblatt y es capáz de clasificar elementos que sean linealmente separables, generando un hiperplano que separe estos en n  dimensiones. Esto quiere decir, que si dibujamos datos que previamente separamos en clases, digamos una clase $C_1$ y $C_2$ donde $C_1$ son buenos clientes y $C_2$ son malos clientes, el algoritmo únicamente podrá clasificarlos si estos pueden ser separados por un plano.\n",
    "\n",
    "\n",
    "**NOTA**: Para esta practica se ha implementado él Perceptron con él uso de las librerias de scikitlearn. En cocnreto se han utilizado la libreria: model_selection, linar_model, preprocessing y metrics para él preprocesamiento de datos y en él entrenamiento de datos Acontinuacion se va a explicar los pasos que se han seguido.\n",
    "\n",
    "- Se han dividido los datos en un **90% de datos de entrenamiento y un 10% de datos de test**\n",
    "- Se han preprocesado los datos para eliminar los datos poco significativos\n",
    "- Se ha creado él Perceptron con SciKitLearn y se ha aplicado a los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#Perceptron for Iris dataBase\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 WINE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "#Perceptron for WINE dataBase\n",
    "iris = datasets.load_wine()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Perceptron for Cancer dataBase\n",
    "iris = datasets.load_breast_cancer()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ISOLET dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "data, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "labels = pd.factorize(y)[0]\n",
    "\n",
    "# Importing the dataset\n",
    "#dataset = dataset\n",
    "X = data \n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# K-Means Clustering for MNIST\n",
    "# ------ MNIST Database ------\n",
    "# 1. Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "labels = pd.factorize(y)[0]\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Conclusión\n",
    "Como hemos visto, el algoritmo de Perceptrón es capaz de devolver un buen resultado (mayor de 80%) en todas las datasets que se han probado. Esto quiere decir que ha sido capaz de clasificar la mayoría de elementos, sin importar el tamaño de la dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensembles-boosting\n",
    "Primero, vamos a hacer una breve descripción a lo que es un ensamble. Un **ensemble** es un conjunto de modelos de machine learning. Cada modelo produce una predicción diferente. Las predicciones de los distintos modelos se combinan para obtener una única predicción.\n",
    "\n",
    "La ventaja que obtenemos al combinar modelos diferentes es que como cada modelo funciona de forma diferente, sus errores tienden a compensarse. Esto resulta en un mejor error de generalización.\n",
    "\n",
    "Hay varias formas de construir estos ensembles:\n",
    "- votación por mayoría\n",
    "- bagging\n",
    "- boosting _(esta practica)_\n",
    "- stacking\n",
    "\n",
    "En el **boosting**, cada modelo intenta arreglar los errores de los modelos anteriores. Por ejemplo, en el caso de clasificación, el primer modelo tratará de aprender la relación entre los atributos de entrada y el resultado. Seguramente cometerá algunos errores. Así que el segundo modelo intentará reducir estos errores. Esto se consigue dándole más peso a las muestras mal clasificadas y menos peso a las muestras bien clasificadas. Para problemas de regresión, las predicciones con un mayor error cuadrático medio tendrán más peso para el siguiente modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  60.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 48 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as sps\n",
    "\n",
    "# Load in the data and define the column labels\n",
    "iris = datasets.load_wine()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\n",
    "for label in y:\n",
    "    X[label] = LabelEncoder().fit(X[label]).transform(X[label])\n",
    "    \n",
    "Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\n",
    "\n",
    "predictions = np.mean(cross_validate(Tree_model,X,y,cv=50)['test_score'])\n",
    "print('The accuracy is: ',predictions*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión modelo inicial train/test  0.962/0.888\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"522pt\" height=\"269pt\"\n",
       " viewBox=\"0.00 0.00 522.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 518,-265 518,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#add6f4\" stroke=\"#000000\" points=\"337.5,-261 173.5,-261 173.5,-193 337.5,-193 337.5,-261\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">worst perimeter &lt;= 106.05</text>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 426</text>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [157, 269]</text>\n",
       "<text text-anchor=\"middle\" x=\"255.5\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#40a1e6\" stroke=\"#000000\" points=\"256.5,-157 70.5,-157 70.5,-89 256.5,-89 256.5,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">worst concave points &lt;= 0.159</text>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 259</text>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9, 250]</text>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M225.3758,-192.9465C217.4332,-183.968 208.7709,-174.1758 200.511,-164.8385\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"202.9392,-162.301 193.6919,-157.13 197.6962,-166.939 202.9392,-162.301\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.1642\" y=\"-178.3833\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#e89152\" stroke=\"#000000\" points=\"423,-157 274,-157 274,-89 423,-89 423,-157\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">worst texture &lt;= 20.645</text>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 167</text>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [148, 19]</text>\n",
       "<text text-anchor=\"middle\" x=\"348.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M285.9517,-192.9465C293.9806,-183.968 302.737,-174.1758 311.0867,-164.8385\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.923,-166.9174 317.9799,-157.13 308.705,-162.2512 313.923,-166.9174\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.3737\" y=\"-178.3911\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#3c9fe5\" stroke=\"#000000\" points=\"105,-53 0,-53 0,0 105,0 105,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 253</text>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 249]</text>\n",
       "<text text-anchor=\"middle\" x=\"52.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M124.3656,-88.9777C113.5167,-79.546 101.7516,-69.3178 90.9426,-59.9208\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.1108,-57.1681 83.2677,-53.2485 88.5181,-62.4508 93.1108,-57.1681\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#ea9a61\" stroke=\"#000000\" points=\"236,-53 123,-53 123,0 236,0 236,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"179.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M169.141,-88.9777C170.5226,-80.6449 172.0073,-71.6903 173.409,-63.2364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.8821,-63.6863 175.065,-53.2485 169.9764,-62.5413 176.8821,-63.6863\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#7bbeee\" stroke=\"#000000\" points=\"382.5,-53 284.5,-53 284.5,0 382.5,0 382.5,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16</text>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 12]</text>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M343.2116,-88.9777C341.9163,-80.6449 340.5244,-71.6903 339.2103,-63.2364\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.6523,-62.5922 337.6578,-53.2485 335.7354,-63.6674 342.6523,-62.5922\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#e68743\" stroke=\"#000000\" points=\"514,-53 401,-53 401,0 514,0 514,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"457.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 151</text>\n",
       "<text text-anchor=\"middle\" x=\"457.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [144, 7]</text>\n",
       "<text text-anchor=\"middle\" x=\"457.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M386.9293,-88.9777C397.5827,-79.546 409.1359,-69.3178 419.7501,-59.9208\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"422.1194,-62.4978 427.2867,-53.2485 417.4793,-57.2566 422.1194,-62.4978\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fec451a3b50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando las librerías que vamos a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import graphviz\n",
    "import xgboost as xgb\n",
    "\n",
    "# graficos incrustados\n",
    "%matplotlib inline\n",
    "\n",
    "# parametros esteticos de seaborn\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "\n",
    "# Utilzando el dataset breast cancer\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# dataset en formato tabular\n",
    "pd.DataFrame(data=cancer.data,\n",
    "            columns=cancer.feature_names).head()\n",
    "\n",
    "# Separando los datos en sets de entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, \n",
    "                        cancer.target, random_state=1)\n",
    "\n",
    "# Armando un simple arbol de decisión\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print('Precisión modelo inicial train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(tree.score(X_train, y_train), tree.score(X_test, y_test)))\n",
    "# Dibujando el modelo\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "feature_names=cancer.feature_names, impurity=False, filled=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión modelo con AdaBoost train/test  1.000/0.965\n"
     ]
    }
   ],
   "source": [
    "# Utilizando AdaBoost para aumentar la precisión\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, \n",
    "                         learning_rate=1.5, random_state=1)\n",
    "ada = ada.fit(X_train, y_train)\n",
    "# Imprimir la precision\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train, y_train_pred)\n",
    "ada_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Precisión modelo con AdaBoost train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(ada_train, ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
