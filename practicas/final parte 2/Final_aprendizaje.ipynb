{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Aprendizaje\n",
    "\n",
    "* **Alumno 1**: Javier Barragán Haro\n",
    "* **Alumno 2**: Victor Nieves Sanchez\n",
    "\n",
    "## 1. Introducción\n",
    "En esta practica se pretende enseñar lo aprendido en las semanas finales de la segunda parte de la asignatura. La idea era poder mostrar lo siguiente:\n",
    "- Algoritmo iterativo tipo perceptrón\n",
    "- Ensembles de clasificadores (variante boosting con un perceptrón como reconocedor de base del ensemble)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptrón\n",
    "El perceptrón es un algoritmo bio inspirado desarrollado por Frank Rosenblatt y es capáz de clasificar elementos que sean linealmente separables, generando un hiperplano que separe estos en n  dimensiones. Esto quiere decir, que si dibujamos datos que previamente separamos en clases, digamos una clase $C_1$ y $C_2$ donde $C_1$ son buenos clientes y $C_2$ son malos clientes, el algoritmo únicamente podrá clasificarlos si estos pueden ser separados por un plano.\n",
    "\n",
    "\n",
    "**NOTA**: Para esta practica se ha implementado él Perceptron con él uso de las librerias de scikitlearn. En cocnreto se han utilizado la libreria: model_selection, linar_model, preprocessing y metrics para él preprocesamiento de datos y en él entrenamiento de datos Acontinuacion se va a explicar los pasos que se han seguido.\n",
    "\n",
    "- Se han dividido los datos en un **90% de datos de entrenamiento y un 10% de datos de test**\n",
    "- Se han preprocesado los datos para eliminar los datos poco significativos\n",
    "- Se ha creado él Perceptron con SciKitLearn y se ha aplicado a los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#Perceptron for Iris dataBase\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 WINE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "#Perceptron for WINE dataBase\n",
    "iris = datasets.load_wine()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "#Perceptron for Cancer dataBase\n",
    "iris = datasets.load_breast_cancer()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ISOLET dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "data, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "labels = pd.factorize(y)[0]\n",
    "\n",
    "# Importing the dataset\n",
    "#dataset = dataset\n",
    "X = data \n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "# K-Means Clustering for MNIST\n",
    "# ------ MNIST Database ------\n",
    "# 1. Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "labels = pd.factorize(y)[0]\n",
    "\n",
    "# Se divide los datos en 90% datos de entrenamiento y 10% datos de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "#Se preprocesan los datos\n",
    "standardSc = StandardScaler()\n",
    "standardSc.fit(X_train)\n",
    "\n",
    "#Se transforma el formato de los vectores\n",
    "X_train_std = standardSc.transform(X_train)\n",
    "X_test_std = standardSc.transform(X_test)\n",
    "\n",
    "perceptron = Perceptron(max_iter=100,eta0=0.1,random_state=0)\n",
    "perceptron.fit(X_train_std,y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test_std)\n",
    "\n",
    "#Se imprime el porcentaje de acierto\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Conclusión\n",
    "Como hemos visto, el algoritmo de Perceptrón es capaz de devolver un buen resultado (mayor de 80%) en todas las datasets que se han probado. Esto quiere decir que ha sido capaz de clasificar la mayoría de elementos, sin importar el tamaño de la dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ensembles-boosting\n",
    "Primero, vamos a hacer una breve descripción a lo que es un ensamble. Un **ensemble** es un conjunto de modelos de machine learning. Cada modelo produce una predicción diferente. Las predicciones de los distintos modelos se combinan para obtener una única predicción.\n",
    "\n",
    "La ventaja que obtenemos al combinar modelos diferentes es que como cada modelo funciona de forma diferente, sus errores tienden a compensarse. Esto resulta en un mejor error de generalización.\n",
    "\n",
    "Hay varias formas de construir estos ensembles:\n",
    "- votación por mayoría\n",
    "- bagging\n",
    "- boosting _(esta practica)_\n",
    "- stacking\n",
    "\n",
    "En el **boosting**, cada modelo intenta arreglar los errores de los modelos anteriores. Por ejemplo, en el caso de clasificación, el primer modelo tratará de aprender la relación entre los atributos de entrada y el resultado. Seguramente cometerá algunos errores. Así que el segundo modelo intentará reducir estos errores. Esto se consigue dándole más peso a las muestras mal clasificadas y menos peso a las muestras bien clasificadas. Para problemas de regresión, las predicciones con un mayor error cuadrático medio tendrán más peso para el siguiente modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  60.8 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 48 members, which is too few. The minimum number of members in any class cannot be less than n_splits=50.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as sps\n",
    "\n",
    "# Load in the data and define the column labels\n",
    "iris = datasets.load_wine()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\n",
    "for label in y:\n",
    "    X[label] = LabelEncoder().fit(X[label]).transform(X[label])\n",
    "    \n",
    "Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\n",
    "\n",
    "predictions = np.mean(cross_validate(Tree_model,X,y,cv=50)['test_score'])\n",
    "print('The accuracy is: ',predictions*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión modelo inicial train/test  0.962/0.888\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    136\u001b[0m         out = backend.pipe(self._engine, format, data,\n\u001b[1;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                            quiet=quiet)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \"\"\"\n\u001b[1;32m    228\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7fec64f59190>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando las librerías que vamos a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import graphviz\n",
    "import xgboost as xgb\n",
    "\n",
    "# graficos incrustados\n",
    "%matplotlib inline\n",
    "\n",
    "# parametros esteticos de seaborn\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (8, 4)})\n",
    "\n",
    "# Utilzando el dataset breast cancer\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# dataset en formato tabular\n",
    "pd.DataFrame(data=cancer.data,\n",
    "            columns=cancer.feature_names).head()\n",
    "\n",
    "# Separando los datos en sets de entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, \n",
    "                        cancer.target, random_state=1)\n",
    "\n",
    "# Armando un simple arbol de decisión\n",
    "tree = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print('Precisión modelo inicial train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(tree.score(X_train, y_train), tree.score(X_test, y_test)))\n",
    "# Dibujando el modelo\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "feature_names=cancer.feature_names, impurity=False, filled=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\r\n",
      "node [shape=box, style=\"filled\", color=\"black\"] ;\r\n",
      "0 [label=\"worst perimeter <= 106.05\\nsamples = 426\\nvalue = [157, 269]\\nclass = benign\", fillcolor=\"#add6f4\"] ;\r\n",
      "1 [label=\"worst concave points <= 0.159\\nsamples = 259\\nvalue = [9, 250]\\nclass = benign\", fillcolor=\"#40a1e6\"] ;\r\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\r\n",
      "2 [label=\"samples = 253\\nvalue = [4, 249]\\nclass = benign\", fillcolor=\"#3c9fe5\"] ;\r\n",
      "1 -> 2 ;\r\n",
      "3 [label=\"samples = 6\\nvalue = [5, 1]\\nclass = malignant\", fillcolor=\"#ea9a61\"] ;\r\n",
      "1 -> 3 ;\r\n",
      "4 [label=\"worst texture <= 20.645\\nsamples = 167\\nvalue = [148, 19]\\nclass = malignant\", fillcolor=\"#e89152\"] ;\r\n",
      "0 -> 4 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\r\n",
      "5 [label=\"samples = 16\\nvalue = [4, 12]\\nclass = benign\", fillcolor=\"#7bbeee\"] ;\r\n",
      "4 -> 5 ;\r\n",
      "6 [label=\"samples = 151\\nvalue = [144, 7]\\nclass = malignant\", fillcolor=\"#e68743\"] ;\r\n",
      "4 -> 6 ;\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Utilizando AdaBoost para aumentar la precisión\n",
    "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, \n",
    "                         learning_rate=1.5, random_state=1)\n",
    "ada = ada.fit(X_train, y_train)\n",
    "# Imprimir la precision\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train, y_train_pred)\n",
    "ada_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Precisión modelo con AdaBoost train/test  {0:.3f}/{1:.3f}'\n",
    "      .format(ada_train, ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
