{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wyjOTFnys8qF"
   },
   "source": [
    "# Reconocimiento de Formas: Práctica Final (6) - OCR\n",
    "\n",
    "En esta práctica final implementarás un OCR capaz de leer una hoja con texto escrito a máquina.\n",
    "\n",
    "* **alumno 1**: Víctor Nieves Sánchez\n",
    "* **alumno 2**: Javier Barragán Haro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcaqXMqas8qJ"
   },
   "source": [
    "Las utilidades **upm_imshow** y **upm_rectangle** te permiten respectivamente mostrar una ventana re-escalable de un tamaño determinado y dibujan un rectángulo representado como [x, y, width, height]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iyglxe27s8qM",
    "outputId": "47ba04a8-ac31-431d-e843-4d0b90d30894"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,30)\n",
    "\n",
    "# %pip install mpld3\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "# ##############################################################################\n",
    "# ################################## Utilities #################################\n",
    "# ##############################################################################\n",
    "\n",
    "fig_counter = [0]\n",
    "    \n",
    "def upm_imshow(win_name, img, win_size=800):\n",
    "    \"\"\"Shows a resizable window with a fixed size. No matters the image size\"\"\"\n",
    "#     cv2.namedWindow(win_name, cv2.WINDOW_KEEPRATIO)\n",
    "#     cv2.imshow(win_name, img)\n",
    "#     h = img.shape[0]\n",
    "#     w = img.shape[1]\n",
    "#     max_dim = w if w > h else h\n",
    "#     win_scale = win_size / max_dim\n",
    "#     cv2.resizeWindow(win_name, int(w * win_scale), int(h * win_scale))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "def upm_rectangle(img, box, color, thickness):\n",
    "    \"\"\"Draws a rectangle based on a box. The box should be: [x, y, width, height]\"\"\"\n",
    "    cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[0] + box[2]), int(box[1] + box[3])), color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzqZsqWNs8qf"
   },
   "source": [
    "## Clasificadores\n",
    "\n",
    "Implementa aquí los clasificadores que vaya a emplear para reconocer cada caracter de forma individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngYX5y4Ps8qh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8l1ahgaw7Sf"
   },
   "source": [
    "# Reconocedor de texto\n",
    "La clase **TextRecognizer** es la encargada de detectar el texto en la imagen con la ayuda de tu reconocedor de caracteres. El reconocimiento de texto tiene los siguientes pasos báásicos:\n",
    "\n",
    "1. Detectar los caracteres como manchas negras sobre el fondo blanco (método **detect_chars**).\n",
    "2. Reconocer el caracter a partir de el trocito de imagen (méétdos **predict_char** y **standardize_char_size**).\n",
    "3. Agrupar los caracteres formando palabras (método **detect_words**)\n",
    "4. Agrupar las palabras formando lineas de texto (método **detect_lines**)\n",
    "\n",
    "Esta clase emplea métodos de visión por computador que están fuera del alcance de la asignatura de reconocimiento de formas. Por este motivo no es necesario que modifiques esta clase, aunque si crees que con ello puedes mejorar de alguna manera tus ratios de detección, te animamos a hacerlo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCA5TJsMs8ql"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d5f29cf535a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ##############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTextRecognizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mTextRecognizer\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mutility\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mallows\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mscanned\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d5f29cf535a9>\u001b[0m in \u001b[0;36mTextRecognizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_classifier\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m     28\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mchar_classifier\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrecognize\u001b[0m \u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from typing import Callable\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "\n",
    "# ##############################################################################\n",
    "# ############################# Text Recognition ###############################\n",
    "# ##############################################################################\n",
    "\n",
    "class TextRecognizer:\n",
    "    \"\"\"\n",
    "    The TextRecognizer class is a utility that allows to detect text in a scanned paper.\n",
    "    The class uses computer vision classical methods to detect characters, words and lines of text.\n",
    "    Characters are detected as dark blobs in the light background. A classifier specified in the\n",
    "    constructor is used to recognize each character individually. Words are detected as big\n",
    "    blobs and its letters are detected as the recognized chars that fall inside the word box.\n",
    "    Last, line text are detected as groups of horizontally aligned word boxes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, char_classifier: (Classifier, BaseEstimator), classifier_mapping: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param char_classifier: The classifier that will be used to recognize characters.\n",
    "        :param classifier_mapping: The mapping from the output of the classifier (number) to chars\n",
    "        \"\"\"\n",
    "        self.char_classifier = None\n",
    "        self.classifier_mapping = classifier_mapping\n",
    "        self.char_classifier = char_classifier\n",
    "\n",
    "    def predict_char(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Predicts a char based on the input bitmap X. Since the char_classifier predicts\n",
    "        a index, this function converts the returned intex into a char.\n",
    "        :param X: The input image with a character to recognize. Should be of type float.\n",
    "        :return: The predicted char.\n",
    "        \"\"\"\n",
    "        assert X.dtype in (float, np.float32, np.float64)\n",
    "        return self.classifier_mapping[self.char_classifier.predict(X.reshape(1, -1))][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def standardize_char_size(img: np.ndarray, dst_shape: tuple = (28, 28)):\n",
    "        \"\"\"\n",
    "        Centers and scales the input image (img) to fit it in a image of shape dst_shape with a small border.\n",
    "        :param img: The input image\n",
    "        :param dst_shape: The destination shape. This defines also the number of features used in the classifier.\n",
    "        :return: a new image where the input image has been scaled and centered.\n",
    "        \"\"\"\n",
    "        dst = np.zeros(dst_shape, dtype=float)\n",
    "        h, w = img.shape\n",
    "        margin = 2\n",
    "        # Scale the image to fit in the destination shape\n",
    "        scale_factor = (dst_shape[0] - 2 * margin) / h if h > w else (dst_shape[1] - 2 * margin) / w\n",
    "        resized = cv2.resize(img, (int(scale_factor * w), int(scale_factor * h)))\n",
    "        # Convert from white background to black background\n",
    "        resized = 255 - resized.astype(float)\n",
    "        # Paste in the output image\n",
    "        x_margin = (dst_shape[1] - resized.shape[1]) // 2\n",
    "        y_margin = (dst_shape[0] - resized.shape[0]) // 2\n",
    "        dst[y_margin:y_margin + resized.shape[0], x_margin:x_margin + resized.shape[1]] = resized\n",
    "        return dst\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_chars(bin_img: np.ndarray, predict_function: Callable):\n",
    "        \"\"\"\n",
    "        Detects chars in the input image.\n",
    "        :param bin_img: A binary image(black and white image with white background)\n",
    "        where the letters are clearly visible and there is no noise!\n",
    "        :param predict_function: A function to date a standardize char image and predict a letter from it.\n",
    "        :return: A numpy array with the char boxes (format [x, y, width , height])\n",
    "        and other numpy array with chars of each box.\n",
    "        \"\"\"\n",
    "        # Reduce the letters thickness to make easier the segmentation\n",
    "        bin_img = cv2.dilate(bin_img, np.ones((3, 3), np.uint8))\n",
    "\n",
    "        # Find the contours of the letters. Chains of pixels around them\n",
    "        _, contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        dbg_img = cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR)\n",
    "        dbg_img = cv2.drawContours(dbg_img, contours, -1, (0, 0, 255), 1)\n",
    "\n",
    "        # Get the most frequently parent as the one of the letters\n",
    "        poss_hierarchy = np.squeeze(hierarchy)[:, 3][np.squeeze(hierarchy)[:, 3] >= 0]\n",
    "        most_freq_parent = np.argmax(np.bincount(poss_hierarchy))\n",
    "        # Discard internal contours\n",
    "        contours = np.array(contours)[np.squeeze(hierarchy)[:, 3] == most_freq_parent]\n",
    "        # Discard small contours that use to be commas, points, accents etc.\n",
    "        contours = contours[np.array(list(map(cv2.contourArea, contours))) > 120]\n",
    "        # Draw the contours in the debug image\n",
    "        dbg_img = cv2.drawContours(dbg_img, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "        # Obtain the bounding boxes that surround each contour(letter)\n",
    "        char_boxes = list(map(cv2.boundingRect, contours))\n",
    "        if len(char_boxes) == 0:\n",
    "            raise ValueError(\"Cannot detect any character!\")\n",
    "\n",
    "        CHAR_ASPECT_RATIO = 0.66  # Width / height\n",
    "        for box in char_boxes:\n",
    "            n_splits = round((box[2] / box[3]) / CHAR_ASPECT_RATIO)\n",
    "            if n_splits > 2:\n",
    "                # We have detected a box that clearly contains two chars\n",
    "                char_boxes.remove(box)\n",
    "                for i in range(n_splits):\n",
    "                    char_boxes.append([int(box[0] + (box[2] / n_splits) * i), box[1], int(box[2] / n_splits), box[3]])\n",
    "\n",
    "        detected_chars = []\n",
    "        for box in char_boxes:\n",
    "            # Crop the char from the full image, standardize the image size and predict its char\n",
    "            cropped_image = bin_img[box[1]:box[1] + box[3], box[0]:box[0] + box[2]]\n",
    "            cropped_image = TextRecognizer.standardize_char_size(cropped_image)\n",
    "            # upm_imshow(\"Letter\", cropped_image)\n",
    "            # cv2.waitKey()\n",
    "            pred_char = predict_function(cropped_image)\n",
    "            detected_chars.append(pred_char)\n",
    "\n",
    "            # Draw the result\n",
    "            upm_rectangle(dbg_img, box, (255, 0, 255), 1)\n",
    "            cv2.putText(dbg_img, pred_char, (box[0], box[1] - 4), 0, 0.7, (255, 0, 255), 2)\n",
    "\n",
    "        # Debug imshows\n",
    "        cv2.circle(dbg_img, (30, 40), 25, (0, 0, 255), -1)\n",
    "        cv2.putText(dbg_img, \"Discarded Contours\", (70, 65), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 4)\n",
    "        cv2.circle(dbg_img, (30, 100), 25, (0, 255, 0), -1)\n",
    "        cv2.putText(dbg_img, \"Contours considered Letters\", (70, 125), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 4)\n",
    "        upm_imshow(\"Detected Chars\", dbg_img)\n",
    "\n",
    "        # Join all the characters in a str\n",
    "        return np.array(char_boxes), np.array(detected_chars)\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_words(bin_img: np.ndarray, char_boxes: np.ndarray, detected_chars: np.ndarray):\n",
    "        \"\"\"\n",
    "        Detects words in the input image given a set of pre-recognized chars.\n",
    "        :param bin_img: A binary image(black and white image with white background)\n",
    "        where the words are clearly visible and there is no noise!\n",
    "        :param char_boxes: A numpy array containing at each row the information of a\n",
    "        char box in format [x, y, width, height].\n",
    "        :param detected_chars: A numpy array with the char of each box.\n",
    "        :return:  A numpy array with the boxes around each word\n",
    "        and other numpy array with the text of each word.\n",
    "        \"\"\"\n",
    "        assert len(char_boxes > 0) and len(detected_chars) == len(char_boxes)\n",
    "\n",
    "        # Take a color copy of the input image for debug purposes\n",
    "        dbg_img = cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        erode_kernel = np.ones((3, 17), np.uint8)\n",
    "        bin_img = cv2.erode(bin_img, erode_kernel)\n",
    "        # upm_imshow(\"Words dilated Image\", bin_img)\n",
    "\n",
    "        # Find the contours of the letters. Chains of pixels around them\n",
    "        _, contours, hierarchy = cv2.findContours(bin_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Discard internal contours\n",
    "        # Get the most frequently parent as the one of the words\n",
    "        poss_hierarchy = np.squeeze(hierarchy)[:, 3][np.squeeze(hierarchy)[:, 3] >= 0]\n",
    "        most_freq_parent = np.argmax(np.bincount(poss_hierarchy))\n",
    "        contours = np.array(contours)[np.squeeze(hierarchy)[:, 3] == most_freq_parent]\n",
    "        word_boxes = list(map(cv2.boundingRect, contours))\n",
    "\n",
    "        if len(word_boxes) == 0:\n",
    "            raise ValueError(\"Cannot detect any word!\")\n",
    "\n",
    "        detected_words = []\n",
    "        # Convert the char boxes to a numpy array\n",
    "        char_boxes = np.squeeze(np.array([char_boxes]))\n",
    "        for box in word_boxes:\n",
    "            inside = np.logical_and(np.logical_and(char_boxes[:, 0] >= box[0],\n",
    "                                                   char_boxes[:, 1] >= box[1]),\n",
    "                                    np.logical_and(char_boxes[:, 0] + char_boxes[:, 2] <= box[0] + box[2],\n",
    "                                                   char_boxes[:, 1] + char_boxes[:, 3] <= box[1] + box[3]))\n",
    "\n",
    "            # Take the order of the boxes by its x-coordinate\n",
    "            chars_order = np.argsort(char_boxes[inside, 0])\n",
    "            # Sort the chars by the ordered indices\n",
    "            word = ''.join(detected_chars[inside][chars_order])\n",
    "            detected_words.append(word)\n",
    "\n",
    "            # Draw the result\n",
    "            upm_rectangle(dbg_img, box, (255, 0, 0), 2)\n",
    "            cv2.putText(dbg_img, word, (box[0], box[1] - 4), 0, 1.2, (255, 0, 0), 3)\n",
    "\n",
    "        upm_imshow(\"Detected Words\", dbg_img)\n",
    "        return np.array(word_boxes), np.array(detected_words)\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_lines(bin_img: np.ndarray, word_boxes: np.ndarray, detected_words: np.ndarray):\n",
    "        \"\"\"\n",
    "        Detects lines in the input image given a set of pre-recognized words.\n",
    "        :param bin_img: A binary image(black and white image with white background).\n",
    "        :param word_boxes: A numpy array with the boxes around each word. Format [x, y, width, height]\n",
    "        :param detected_words: Numpy array with the text of each word.\n",
    "        :return: A list with each text line detected in the document. A text line is\n",
    "         represented by a dictionary with the following entries:\n",
    "         - line_box: A box around the words in the text line. Format: [x, y, width, height]\n",
    "         - word_boxes: A numpy array with the word boxes inside the text line.\n",
    "         - words: A numpy array with the words in the line.\n",
    "        \"\"\"\n",
    "        assert len(word_boxes > 0) and len(detected_words) == len(word_boxes)\n",
    "\n",
    "        # Sort the words by its X coordinate\n",
    "        left_order_idx = np.argsort(word_boxes[:, 0])\n",
    "        boxes_to_take = word_boxes[left_order_idx].copy()\n",
    "        words_to_take = detected_words[left_order_idx].copy()\n",
    "\n",
    "        dbg_img = cv2.cvtColor(bin_img, cv2.COLOR_GRAY2BGR)\n",
    "        lines = []\n",
    "        # For each line in the document\n",
    "        while len(boxes_to_take) > 0:\n",
    "            initial_center = boxes_to_take[0, :2] + boxes_to_take[0, 2:] / 2\n",
    "\n",
    "            # Select the boxes at the same height that the initial_box\n",
    "            aligned = np.logical_and(boxes_to_take[:, 1] <= initial_center[1],\n",
    "                                     boxes_to_take[:, 1] + boxes_to_take[:, 3] >= initial_center[1])\n",
    "            aligned = np.argwhere(aligned).flatten()\n",
    "\n",
    "            # Sort selected words from left to right\n",
    "            selected_indices = np.argsort(boxes_to_take[aligned, 0].flatten())\n",
    "            selected_boxes = boxes_to_take[aligned][selected_indices]\n",
    "            selected_words = words_to_take[aligned][selected_indices]\n",
    "            # Create line bix in format: [x, y, width, height]\n",
    "            line_box = [selected_boxes[:, 0].min(),\n",
    "                        selected_boxes[:, 1].min(),\n",
    "                        np.max(selected_boxes[:, 0] + selected_boxes[:, 2]) - selected_boxes[:, 0].min(),\n",
    "                        np.max(selected_boxes[:, 1] + selected_boxes[:, 3]) - selected_boxes[:, 1].min()]\n",
    "\n",
    "            if line_box[2] * line_box[3] > 1500:\n",
    "                # Append the line to the list if it is big\n",
    "                lines.append({'line_box': line_box, 'word_boxes': selected_boxes, 'words': selected_words})\n",
    "\n",
    "                # Draw the result\n",
    "                upm_rectangle(dbg_img, line_box, (255, 0, 255), 3)\n",
    "                line_text = functools.reduce(lambda a, b: a + ' ' + b, selected_words)\n",
    "                cv2.putText(dbg_img, line_text, (line_box[0], line_box[1] - 6), 0, 1.2, (255, 0, 255), 3)\n",
    "\n",
    "            # Delete selected element\n",
    "            mask = np.ones(len(boxes_to_take), np.bool)\n",
    "            mask[aligned] = 0\n",
    "            boxes_to_take = boxes_to_take[mask]\n",
    "            words_to_take = words_to_take[mask]\n",
    "\n",
    "        upm_imshow(\"Detected Lines\", dbg_img)\n",
    "        # Sort the lines by its Y coordinates\n",
    "        lines.sort(key=lambda l: l['line_box'][1])\n",
    "        return lines\n",
    "\n",
    "    def detect_image_text(self, image_path: str):\n",
    "        \"\"\"\n",
    "        Detects text in an image of a scanned sheet paper. Text should be written in\n",
    "        :param image_path: The path where the image is stored on disk.\n",
    "        :return: The detected text lines and the full text.\n",
    "        \"\"\"\n",
    "        # Read the input image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(\"Cannot find file \\\"{}\\\"\".format(image_path))\n",
    "        assert img.shape[0] > img.shape[1], \"Error: The image should be a portrait paper.\"\n",
    "\n",
    "        # Resize image to a fixed processing size\n",
    "        IMG_WIDTH = 2500.0  # pixels\n",
    "        scale_factor = IMG_WIDTH / img.shape[1]\n",
    "        img = cv2.resize(img, (int(scale_factor * img.shape[1]), int(scale_factor * img.shape[0])))\n",
    "\n",
    "        # Blur image to remove some noise\n",
    "        blur = cv2.GaussianBlur(img, (5, 3), 1)\n",
    "        # upm_imshow(\"Blurred Image\", blur)\n",
    "\n",
    "        # Binarize image using the smart Otsu binarization method\n",
    "        bin_img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        # upm_imshow(\"Binary Image\", bin_img)\n",
    "\n",
    "        # Detect individual chars\n",
    "        char_boxes, detected_chars = self.detect_chars(bin_img, self.predict_char)\n",
    "        # Detect words based on the detected chars\n",
    "        word_boxes, detected_words = self.detect_words(bin_img, char_boxes, detected_chars)\n",
    "        # Detect text lines based on the detected words\n",
    "        lines = self.detect_lines(bin_img, word_boxes, detected_words)\n",
    "\n",
    "        # convert from the lines dictionary format to a string with all the text\n",
    "        text = ''\n",
    "        line_words = []\n",
    "        for l in lines:\n",
    "            line_words.append(l['words'])\n",
    "            text += functools.reduce(lambda a, b: a + ' ' + b, l['words']) + '\\n'\n",
    "\n",
    "        return line_words, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdYogJJ3y5A_"
   },
   "source": [
    "## Entrenamiento del reconocedor de caracteres\n",
    "\n",
    "Dado que no siempre existe una base de datos que cumpla todos nuestros requisitos, en esta prááctica os proporcionamos el cóódigo para que generééis vuestra propia base de datos de caracteres. La aproximación que os proponemos es la más inocente de todas: una base de datos sintéética.\n",
    "\n",
    "En este código se genera una base de datos donde cada ejemplo es la imagen de un caracter. Las imágenes se generan empleando la librería de python **PIL** en el méétdo **generate_ttf_images**. Para dotar de un poco de realismo a la base de datos se añaden distintos tipos de ruido con la función **add_noise_to_img**. Por úúltimo las imágenes se binarizan y se escalan a una imagen de 28 x 28, empleando el mismo método que se emplea en la clase TextRecognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LpJJpnzVs8qq"
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# ########################### Dataset Generation ###############################\n",
    "# ##############################################################################\n",
    "\n",
    "def add_noise_to_img(img, rot_noise_level=3, scale_noise_level=0.06, gauss_noise_level=20, blur_noise_level=6,\n",
    "                     salt_level=1, dilate_level=11):\n",
    "\n",
    "    img = cv2.dilate(img, np.ones((dilate_level, dilate_level), np.uint8))\n",
    "\n",
    "    # salt and pepper\n",
    "    for _ in range(int(img.shape[0] * salt_level)):\n",
    "        img[np.random.randint(0, img.shape[0]), np.random.randint(0, img.shape[1])] = random.randint(0, 255)\n",
    "\n",
    "    blur_level = random.randint(0, blur_noise_level) * 2 + 1\n",
    "    img = cv2.GaussianBlur(img, (blur_level, blur_level), 1)\n",
    "    rot_noise = 2 * rot_noise_level * np.random.normal() - rot_noise_level\n",
    "    scale_noise = 1 + 2 * scale_noise_level * np.random.normal() - scale_noise_level\n",
    "    A = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), rot_noise, scale_noise)\n",
    "    noisy = cv2.warpAffine(img, A, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    pixel_noise = np.random.normal(size=noisy.shape) * gauss_noise_level\n",
    "    noisy = np.clip(noisy.astype(float) + pixel_noise, 0, 255).astype(np.uint8)\n",
    "    # upm_imshow(\"After\", noisy)\n",
    "    # cv2.waitKey()\n",
    "\n",
    "    return noisy\n",
    "\n",
    "\n",
    "def generate_ttf_images(ttf_filename, n_samples, chars_to_gen):\n",
    "    from PIL import ImageDraw, Image, ImageFont\n",
    "\n",
    "    font = ImageFont.truetype(ttf_filename, 220)\n",
    "\n",
    "    X = []\n",
    "    labels = []\n",
    "    for i in range(len(chars_to_gen)):\n",
    "        for _ in range(n_samples):\n",
    "            c = chars_to_gen[i]\n",
    "            gen_shape = (200, 200)\n",
    "            image = Image.new('RGB', gen_shape)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "\n",
    "            draw.text((25, 20), c, font=font)\n",
    "            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Add noise\n",
    "            img = add_noise_to_img(img)\n",
    "\n",
    "            img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            _, contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = np.array(contours)\n",
    "            contours = contours[np.array(list(map(cv2.contourArea, contours))) > 20]\n",
    "            char_box = cv2.boundingRect(contours[0])\n",
    "            char_crop = img[char_box[1]:char_box[1] + char_box[3], char_box[0]:char_box[0] + char_box[2]]\n",
    "            img = TextRecognizer.standardize_char_size(255 - char_crop)\n",
    "            X.append(img)\n",
    "            labels.append(i)\n",
    "            # upm_imshow(\"Img\", img)\n",
    "            # cv2.waitKey()\n",
    "\n",
    "    return np.array(X), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "XdhMGUrgs8qy",
    "outputId": "e7cd1a2c-f8e1-4b98-9438-9094fe20b198",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/victor/Descargas/asignaturas/reconocimiento de formas/reconocimiento-de-formas/practicas/Reconocimiento de texto/resources\n",
      "################################################################################\n",
      "########################## Text Recognition Example ############################\n",
      "################################################################################\n",
      "--> Generating training dataset\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d96a35d4d084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                    ])\n\u001b[1;32m     24\u001b[0m \u001b[0mfont_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AndaleMono.ttf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_ttf_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4a4408ec95bf>\u001b[0m in \u001b[0;36mgenerate_ttf_images\u001b[0;34m(ttf_filename, n_samples, chars_to_gen)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Loading Isolet indices from Drive\n",
    "#from google.colab import drive\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "\n",
    "#drive.mount('/content/gdrive')\n",
    "#resources_dir = '/content/gdrive/My Drive/Colab Notebooks/RF19/Practica6/resources'\n",
    "resources_dir = current_path + '/resources'\n",
    "print(resources_dir)\n",
    "\n",
    "\n",
    "print(\"################################################################################\")\n",
    "print(\"########################## Text Recognition Example ############################\")\n",
    "print(\"################################################################################\")\n",
    "\n",
    "print(\"--> Generating training dataset\")\n",
    "labels = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H',\n",
    "                   'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "                   ])\n",
    "font_filename = os.path.join(resources_dir, \"AndaleMono.ttf\")\n",
    "X_train, y_train = generate_ttf_images(font_filename, 50, labels)\n",
    "X_train = X_train.reshape(len(X_train), -1).astype(float)\n",
    "\n",
    "print(\"--> Generating test dataset\")\n",
    "X_test, y_test = generate_ttf_images(font_filename, 10, labels)\n",
    "X_test = X_test.reshape(len(X_test), -1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "gdSrIavfalEF",
    "outputId": "af28c7f3-5265-497b-ada4-1cba78b78b91"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-191d519ac707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAHWCAYAAADzUtndAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dQYhkd7n/4e/7z5h4yUJBswhJYBIMhnBxkTQhi4sIQYhZZBZxETcaUQbRcLc34ELIxutKEIMyaEh0kQSzaoMiooLchTE9oDFRIm1AMiHgmEg2chMHfv9F13Wqenrs078+VT3V53mgoavqdPU5PR/exUtVTbXWAgAAAMC0/b+jPgEAAAAAjp4lEQAAAACWRAAAAABYEgEAAAAQSyIAAAAAYkkEAAAAQAYsiarq8ar6S1W9dJnHq6q+UVXbVfViVd0x/mmyjrRDD93QSzv00A29tEMP3dBLO6zKkFcSPZHk3n/x+CeS3Dr7Op3kW4c/LY6JJ6IdDu6J6IY+T0Q7HNwT0Q19noh2OLgnohv6PBHtsAL7Lolaa79M8ta/OORUku+1Hb9K8v6qun6sE2R9aYceuqGXduihG3pphx66oZd2WJUxPpPohiSvzd0+N7sP9qMdeuiGXtqhh27opR166IZe2mEUJ1b5y6rqdHZe+pZrr732zttuu22Vv54VOXv27F9ba9eN+ZzaOf50Q6+x29HNNJg59DJz6GHm0MvMocdhuhljSfR6kpvmbt84u+8SrbUzSc4kycbGRtva2hrh13Olqao/DzxUO/yTbug1dju6mQYzh15mDj3MHHqZOfQ4QDeXGOPtZptJPj37NPW7k7zdWntjhOfl+NMOPXRDL+3QQzf00g49dEMv7TCKfV9JVFVPJflYkg9W1bkkX0nyniRprX07yY+S3JdkO8nfk3x2WSfLetEOPXRDL+3QQzf00g49dEMv7bAq+y6JWmuf2ufxluRLo50Rx4Z26KEbemmHHrqhl3booRt6aYdVGePtZgAAAACsOUsiAAAAACyJAAAAALAkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAABk4JKoqu6tqleqaruqHtnj8Yeq6nxV/Wb29fnxT5V1oxt6aYceuqGXduihG3pphx66YVVO7HdAVV2V5LEkH09yLskLVbXZWvv9rkOfaa09vIRzZA3phl7aoYdu6KUdeuiGXtqhh25YpSGvJLoryXZr7dXW2rtJnk5yarmnxTGgG3pphx66oZd26KEbemmHHrphZYYsiW5I8trc7XOz+3Z7oKperKpnq+qmvZ6oqk5X1VZVbZ0/f77jdFkjo3WTaGdizBx66IZe2qGHbuilHXrohpUZ64Orf5jkZGvtI0l+muTJvQ5qrZ1prW201jauu+66kX41a2xQN4l2uISZQw/d0Es79NANvbRDD90wiiFLoteTzG8hb5zd90+ttTdba+/Mbn4nyZ3jnB5rTDf00g49dEMv7dBDN/TSDj10w8oMWRK9kOTWqrq5qq5O8mCSzfkDqur6uZv3J/nDeKfImtINvbRDD93QSzv00A29tEMP3bAy+/7vZq21C1X1cJKfJLkqyeOttZer6tEkW621zST/WVX3J7mQ5K0kDy3xnFkDuqGXduihG3pphx66oZd26KEbVqlaa0fyizc2NtrW1taR/G6Wq6rOttY2lvX82jmedEOvZbajm+PLzKGXmUMPM4deZg49DtPNWB9cDQAAAMAasyQCAAAAwJIIAAAAAEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAADJwSVRV91bVK1W1XVWP7PH4NVX1zOzx56vq5NgnyvrRDb20Qw/d0Es79NANvbRDD92wKvsuiarqqiSPJflEktuTfKqqbt912OeS/K219qEkX0/ytbFPlPWiG3pphx66oZd26KEbemmHHrphlYa8kuiuJNuttVdba+8meTrJqV3HnEry5Oz7Z5PcU1U13mmyhnRDL+3QQzf00g49dEMv7dBDN6zMkCXRDUlem7t9bnbfnse01i4keTvJB8Y4QdaWbuilHXrohl7aoYdu6KUdeuiGlTmxyl9WVaeTnJ7dfKeqXlrl7z9CH0zy16M+iRX68NhPqJ1J0M14ptRNMnI7E+4mmVY7Zs54ptRNYuaMaUrtmDnjmVI3iZkzpim1093NkCXR60lumrt94+y+vY45V1UnkrwvyZu7n6i1dibJmSSpqq3W2kbPSa+bKV1rsnO9GbGbRDtHfR6rMOsmMXMObUrXmow/c6baTTKt6zVzxjOla03MnDFN6XrNnPFM6VoTM2dMU7reuZlzYEPebvZCklur6uaqujrJg0k2dx2zmeQzs+8/meTnrbXWe1IcC7qhl3booRt6aYceuqGXduihG1Zm31cStdYuVNXDSX6S5Kokj7fWXq6qR5NstdY2k3w3yferajvJW9mJlgnTDb20Qw/d0Es79NANvbRDD92wSnVUy8WqOj17qduxN6VrTZZ/vVP6e7rW9Xn+K8mUrjVZ7vX6Wx5fZs54pnStiZkzpildr5kznilda2LmjGlK13uYaz2yJREAAAAAV44hn0kEAAAAwDG39CVRVd1bVa9U1XZVPbLH49dU1TOzx5+vqpPLPqdlGXCtD1XV+ar6zezr80dxnmOoqser6i+X+y8Ta8c3Zn+LF6vqjgM+/2S6SabTzrK7mT3HZNqZSjeJmTO2qbRj5oxrKt0kZs6YdLPwuJlzANpZeNzMGUg3C4/3ddNaW9pXdj5U609JbklydZLfJrl91zFfTPLt2fcPJnlmmed0xNf6UJJvHvW5jnS9H01yR5KXLvP4fUl+nKSS3J3ked1oZ5ndTK2dKXWz7Ham1M3U2jFzdHMltqMb3Zg52lllO7rRzUG7WfYrie5Kst1ae7W19m6Sp5Oc2nXMqSRPzr5/Nsk9VVVLPq9lGHKtx0Zr7ZfZ+dT8yzmV5Httx6+SvL+qrh/49FPqJplQO0vuJplWO5PpJjFzRjaZdsycUU2mm8TMGZFuFpk5w2lnkZkzjG4WdXWz7CXRDUlem7t9bnbfnse01i4keTvJB5Z8Xssw5FqT5IHZS72eraqbVnNqR2Lo36P3Z49LN4l25h2mm6E/f1za0c0iM2c47Vxk5gynm0VmzjC6WWTmDKedRWbOMLpZ1NXNvkuiVby3dkJ+mORka+0jSX6ai9va4+oR7YxmSu3oZjxT6ibRzpim1I5uxjOlbhLtjEU3c3RzINqZo53BptbNgQ15JdETSe79F49/Ismts6/TSb4199jrSeY3czfO7stex1TViSTvS/LmgPO60ux7ra21N1tr78xufifJnSs6t6PwepKzudjOXv/2l2tnSt0k2pl3mG7+7+en0o5uFpk5w2nnIjNnON0sMnOG0c0iM2c47Swyc4bRzaIh//aX2HdJdMj3ub2Q5Naqurmqrs7Oh2Bt7vr5zSSfmX3/ySQ/b23nU5bWzL7Xuuv9f/cn+cMKz2/VNrPzntC3kvxbkrdba2/sOuZy7Uypm0Q78w7TTTKtdnSzyMwZTjsXmTnD6WaRmTOMbhaZOcNpZ5GZM4xuFm0m+fTsVWZ3Z+9uLtWGfWr2yVz+E7OfS/Ifc7d/lmRj7vZ9Sf6YnU8Z//LsvkeT3D/7/r1JfpBkO8mvk9wy5JyuxK8B1/rVJC9n51PWf5HktqM+50Nc61NJ3kjyj+y8t/FzSb6Q5AuzxyvJY0n+nOR/55sY0s6UuplSO8vuZmrtTKWbVbQzpW6m1I6Zo5srtR3d6MbM0c4q29HN5Lv5U5Lf7dXNXl81++F/qapOJnmutfbvezz2XJL/bq39z+z2z5L8V2tta49jT2fnpW+59tpr77ztttv2/d2sn7Nnz/61tXZdoh2G0w29xm5HN9Ng5tDLzKGHmUMvM4ce890c1IkRfv/g97m11s4kOZMkGxsbbWvrklnHMVBVfx54qHb4J93Qa+x2dDMNZg69zBx6mDn0MnPocYBuLjHkg6v30/c+N9AOfXRDL+3QQzf00g49dEMv7TCKfV9JVFVPJflYkg9W1bkkX0nyniRprX07yY+y876/7SR/T/LZZZ0s60U79NANvbRDD93QSzv00A29tMOq7Lskaq19ap/HW5IvjXZGHBvaoYdu6KUdeuiGXtqhh27opR1WZYy3mwEAAACw5iyJAAAAALAkAgAAAMCSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAACQgUuiqrq3ql6pqu2qemSPxx+qqvNV9ZvZ1+fHP1XWjW7opR166IZe2qGHbuilHXrohlU5sd8BVXVVkseSfDzJuSQvVNVma+33uw59prX28BLOkTWkG3pphx66oZd26KEbemmHHrphlYa8kuiuJNuttVdba+8meTrJqeWeFseAbuilHXrohl7aoYdu6KUdeuiGlRmyJLohyWtzt8/N7tvtgap6saqeraqb9nqiqjpdVVtVtXX+/PmO02WNjNZNop2JMXPooRt6aYceuqGXduihG1ZmrA+u/mGSk621jyT5aZIn9zqotXamtbbRWtu47rrrRvrVrLFB3STa4RJmDj10Qy/t0EM39NIOPXTDKIYsiV5PMr+FvHF23z+11t5srb0zu/mdJHeOc3qsMd3QSzv00A29tEMP3dBLO/TQDSszZEn0QpJbq+rmqro6yYNJNucPqKrr527en+QP450ia0o39NIOPXRDL+3QQzf00g49dMPK7Pu/m7XWLlTVw0l+kuSqJI+31l6uqkeTbLXWNpP8Z1Xdn+RCkreSPLTEc2YN6IZe2qGHbuilHXrohl7aoYduWKVqrR3JL97Y2GhbW1tH8rtZrqo621rbWNbza+d40g29ltmObo4vM4deZg49zBx6mTn0OEw3Y31wNQAAAABrzJIIAAAAAEsiAAAAACyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAMjAJVFV3VtVr1TVdlU9ssfj11TVM7PHn6+qk2OfKOtHN/TSDj10Qy/t0EM39NIOPXTDquy7JKqqq5I8luQTSW5P8qmqun3XYZ9L8rfW2oeSfD3J18Y+UdaLbuilHXrohl7aoYdu6KUdeuiGVRrySqK7kmy31l5trb2b5Okkp3YdcyrJk7Pvn01yT1XVeKfJGtINvbRDD93QSzv00A29tEMP3bAyQ5ZENyR5be72udl9ex7TWruQ5O0kHxjjBFlbuqGXduihG3pphx66oZd26KEbVubEKn9ZVZ1Ocnp2852qemmVv/8IfTDJX4/6JFbow2M/oXYmQTfjmVI3ycjtTLibZFrtmDnjmVI3iZkzpim1Y+aMZ0rdJGbOmKbUTnc3Q5ZErye5ae72jbP79jrmXFWdSPK+JG/ufqLW2pkkZ5KkqrZaaxs9J71upnStyc71ZsRuEu0c9XmswqybxMw5tCldazL+zJlqN8m0rtfMGc+UrjUxc8Y0pes1c8YzpWtNzJwxTel652bOgQ15u9kLSW6tqpur6uokDybZ3HXMZpLPzL7/ZJKft9Za70lxLOiGXtqhh27opR166IZe2qGHbliZfV9J1Fq7UFUPJ/lJkquSPN5ae7mqHk2y1VrbTPLdJN+vqu0kb2UnWiZMN/TSDj10Qy/t0EM39NIOPXTDKtVRLRer6vTspW7H3pSuNVn+9U7p7+la1+f5ryRTutZkudfrb3l8mTnjmdK1JmbOmKZ0vWbOeKZ0rYmZM6YpXe9hrvXIlkQAAAAAXDmGfCYRAAAAAMfc0pdEVXVvVb1SVdtV9cgej19TVc/MHn++qk4u+5yWZcC1PlRV56vqN7Ovzx/FeY6hqh6vqr9c7r9MrB3fmP0tXqyqOw74/JPpJplOO8vuZvYck2lnKt0kZs7YptKOmTOuqXSTmDlj0s3C42bOAWhn4XEzZyDdLDze101rbWlf2flQrT8luSXJ1Ul+m+T2Xcd8Mcm3Z98/mOSZZZ7TEV/rQ0m+edTnOtL1fjTJHUleuszj9yX5cZJKcneS53WjnWV2M7V2ptTNstuZUjdTa8fM0c2V2I5udGPmaGeV7ehGNwftZtmvJLoryXZr7dXW2rtJnk5yatcxp5I8Ofv+2ST3VFUt+byWYci1HhuttV9m51PzL+dUku+1Hb9K8v6qun7g00+pm2RC7Sy5m2Ra7Uymm8TMGdlk2jFzRjWZbhIzZ0S6WWTmDKedRWbOMLpZ1NXNspdENyR5be72udl9ex7TWruQ5O0kH1jyeS3DkGtNkgdmL/V6tqpuWs2pHYmhf4/enz0u3STamXeYbob+/HFpRzeLzJzhtHORmTOcbhaZOcPoZpGZM5x2Fpk5w+hmUVc3+y6JVvHe2gn5YZKTrbWPJPlpLm5rj6tHtDOaKbWjm/FMqZtEO2OaUju6Gc+Uukm0MxbdzNHNgWhnjnYGm1o3BzbklURPJLn3Xzz+iSS3zr5OJ/nW3GOvJ5nfzN04uy97HVNVJ5K8L8mbA87rSrPvtbbW3mytvTO7+Z0kd67o3I7C60nO5mI7e/3bX66dKXWTaGfeYbr5v5+fSju6WWTmDKedi8yc4XSzyMwZRjeLzJzhtLPIzBlGN4uG/NtfYt8l0SHf5/ZCklur6uaqujo7H4K1uevnN5N8Zvb9J5P8vLWdT1laM/te6673/92f5A8rPL9V28zOe0LfSvJvSd5urb2x65jLtTOlbhLtzDtMN8m02tHNIjNnOO1cZOYMp5tFZs4wullk5gynnUVmzjC6WbSZ5NOzV5ndnb27uVQb9qnZJ3P5T8x+Lsl/zN3+WZKNudv3Jfljdj5l/Muz+x5Ncv/s+/cm+UGS7SS/TnLLkHO6Er8GXOtXk7ycnU9Z/0WS2476nA9xrU8leSPJP7Lz3sbPJflCki/MHq8kjyX5c5L/nW9iSDtT6mZK7Sy7m6m1M5VuVtHOlLqZUjtmjm6u1HZ0oxszRzurbEc3k+/mT0l+t1c3e33V7If/pao6meS51tq/7/HYc0n+u7X2P7PbP0vyX621rT2OPZ2dl77l2muvvfO2227b93ezfs6ePfvX1tp1iXYYTjf0Grsd3UyDmUMvM4ceZg69zBx6zHdzUCdG+P2D3+fWWjuT5EySbGxstK2tS2Ydx0BV/Xngodrhn3RDr7Hb0c00mDn0MnPoYebQy8yhxwG6ucSQD67eT9/73EA79NENvbRDD93QSzv00A29tMMo9n0lUVU9leRjST5YVeeSfCXJe5KktfbtJD/Kzvv+tpP8Pclnl3WyrBft0EM39NIOPXRDL+3QQzf00g6rsu+SqLX2qX0eb0m+NNoZcWxohx66oZd26KEbemmHHrqhl3ZYlTHebgYAAADAmrMkAgAAAMCSCAAAAABLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABABi6Jqureqnqlqrar6pE9Hn+oqs5X1W9mX58f/1RZN7qhl3booRt6aYceuqGXduihG1blxH4HVNVVSR5L8vEk55K8UFWbrbXf7zr0mdbaw0s4R9aQbuilHXrohl7aoYdu6KUdeuiGVRrySqK7kmy31l5trb2b5Okkp5Z7WhwDuqGXduihG3pphx66oZd26KEbVmbIkuiGJK/N3T43u2+3B6rqxap6tqpu2uuJqup0VW1V1db58+c7Tpc1Mlo3iXYmxsyhh27opR166IZe2qGHbliZsT64+odJTrbWPpLkp0me3Oug1tqZ1tpGa23juuuuG+lXs8YGdZNoh0uYOfTQDb20Qw/d0Es79NANoxiyJHo9yfwW8sbZff/UWnuztfbO7OZ3ktw5zumxxnRDL+3QQzf00g49dEMv7dBDN6zMkCXRC0luraqbq+rqJA8m2Zw/oKqun7t5f5I/jHeKrCnd0Es79NANvbRDD93QSzv00A0rs+//btZau1BVDyf5SZKrkjzeWnu5qh5NstVa20zyn1V1f5ILSd5K8tASz5k1oBt6aYceuqGXduihG3pphx66YZWqtXYkv3hjY6NtbW0dye9muarqbGttY1nPr53jSTf0WmY7ujm+zBx6mTn0MHPoZebQ4zDdjPXB1QAAAACsMUsiAAAAACyJAAAAALAkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACADl0RVdW9VvVJV21X1yB6PX1NVz8wef76qTo59oqwf3dBLO/TQDb20Qw/d0Es79NANq7LvkqiqrkryWJJPJLk9yaeq6vZdh30uyd9aax9K8vUkXxv7RFkvuqGXduihG3pphx66oZd26KEbVmnIK4nuSrLdWnu1tfZukqeTnNp1zKkkT86+fzbJPVVV450ma0g39NIOPXRDL+3QQzf00g49dMPKDFkS3ZDktbnb52b37XlMa+1CkreTfGCME2Rt6YZe2qGHbuilHXrohl7aoYduWJkTq/xlVXU6yenZzXeq6qVV/v4j9MEkfz3qk1ihD4/9hNqZBN2MZ0rdJCO3M+Fukmm1Y+aMZ0rdJGbOmKbUjpkznil1k5g5Y5pSO93dDFkSvZ7kprnbN87u2+uYc1V1Isn7kry5+4laa2eSnEmSqtpqrW30nPS6mdK1JjvXmxG7SbRz1OexCrNuEjPn0KZ0rcn4M2eq3STTul4zZzxTutbEzBnTlK7XzBnPlK41MXPGNKXrnZs5Bzbk7WYvJLm1qm6uqquTPJhkc9cxm0k+M/v+k0l+3lprvSfFsaAbemmHHrqhl3booRt6aYceumFl9n0lUWvtQlU9nOQnSa5K8nhr7eWqejTJVmttM8l3k3y/qraTvJWdaJkw3dBLO/TQDb20Qw/d0Es79NANq1RHtVysqtOzl7ode1O61mT51zulv6drXZ/nv5JM6VqT5V6vv+XxZeaMZ0rXmpg5Y5rS9Zo545nStSZmzpimdL2HudYjWxIBAAAAcOUY8plEAAAAABxzS18SVdW9VfVKVW1X1SN7PH5NVT0ze/z5qjq57HNalgHX+lBVna+q38y+Pn8U5zmGqnq8qv5yuf8ysXZ8Y/a3eLGq7jjg80+mm2Q67Sy7m9lzTKadqXSTmDljm0o7Zs64ptJNYuaMSTcLj5s5B6CdhcfNnIF0s/B4XzettaV9ZedDtf6U5JYkVyf5bZLbdx3zxSTfnn3/YJJnlnlOR3ytDyX55lGf60jX+9EkdyR56TKP35fkx0kqyd1JnteNdpbZzdTamVI3y25nSt1MrR0zRzdXYju60Y2Zo51VtqMb3Ry0m2W/kuiuJNuttVdba+8meTrJqV3HnEry5Oz7Z5PcU1W15PNahiHXemy01n6ZnU/Nv5xTSb7Xdvwqyfur6vqBTz+lbpIJtbPkbpJptTOZbhIzZ2STacfMGdVkuknMnBHpZpGZM5x2Fpk5w+hmUVc3y14S3ZDktbnb52b37XlMa+1CkreTfGDJ57UMQ641SR6YvdTr2aq6aTWndiSG/j16f/a4dJNoZ95huhn688elHd0sMnOG085FZs5wullk5gyjm0VmznDaWWTmDKObRV3d7LskWsV7ayfkh0lOttY+kuSnubitPa4e0c5optSObsYzpW4S7YxpSu3oZjxT6ibRzlh0M0c3B6KdOdoZbGrdHNiQVxI9keTef/H4J5LcOvs6neRbc4+9nmR+M3fj7L7sdUxVnUjyviRvDjivK82+19pae7O19s7s5neS3LmiczsKryc5m4vt7PVvf7l2ptRNop15h+nm/35+Ku3oZpGZM5x2LjJzhtPNIjNnGN0sMnOG084iM2cY3Swa8m9/iX2XRId8n9sLSW6tqpur6ursfAjW5q6f30zymdn3n0zy89Z2PmVpzex7rbve/3d/kj+s8PxWbTM77wl9K8m/JXm7tfbGrmMu186Uukm0M+8w3STTakc3i8yc4bRzkZkznG4WmTnD6GaRmTOcdhaZOcPoZtFmkk/PXmV2d/bu5lJt2Kdmn8zlPzH7uST/MXf7Z0k25m7fl+SP2fmU8S/P7ns0yf2z79+b5AdJtpP8OsktQ87pSvwacK1fTfJydj5l/RdJbjvqcz7EtT6V5I0k/8jOexgTW94AABS+SURBVBs/l+QLSb4we7ySPJbkz0n+d76JIe1MqZsptbPsbqbWzlS6WUU7U+pmSu2YObq5UtvRjW7MHO2ssh3dTL6bPyX53V7d7PVVsx/+l6rqZJLnWmv/vsdjzyX579ba/8xu/yzJf7XWtvY49nR2XvqWa6+99s7bbrtt39/N+jl79uxfW2vXJdphON3Qa+x2dDMNZg69zBx6mDn0MnPoMd/NQZ0Y4fcPfp9ba+1MkjNJsrGx0ba2Lpl1HANV9eeBh2qHf9INvcZuRzfTYObQy8yhh5lDLzOHHgfo5hJDPrh6P33vcwPt0Ec39NIOPXRDL+3QQzf00g6j2PeVRFX1VJKPJflgVZ1L8pUk70mS1tq3k/woO+/7207y9ySfXdbJsl60Qw/d0Es79NANvbRDD93QSzusyr5Lotbap/Z5vCX50mhnxLGhHXrohl7aoYdu6KUdeuiGXtphVcZ4uxkAAAAAa86SCAAAAABLIgAAAAAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAGbgkqqp7q+qVqtquqkf2ePyhqjpfVb+ZfX1+/FNl3eiGXtqhh27opR166IZe2qGHbliVE/sdUFVXJXksyceTnEvyQlVtttZ+v+vQZ1prDy/hHFlDuqGXduihG3pphx66oZd26KEbVmnIK4nuSrLdWnu1tfZukqeTnFruaXEM6IZe2qGHbuilHXrohl7aoYduWJkhS6Ibkrw2d/vc7L7dHqiqF6vq2aq6aa8nqqrTVbVVVVvnz5/vOF3WyGjdJNqZGDOHHrqhl3booRt6aYceumFlxvrg6h8mOdla+0iSnyZ5cq+DWmtnWmsbrbWN6667bqRfzRob1E2iHS5h5tBDN/TSDj10Qy/t0EM3jGLIkuj1JPNbyBtn9/1Ta+3N1to7s5vfSXLnOKfHGtMNvbRDD93QSzv00A29tEMP3bAyQ5ZELyS5tapurqqrkzyYZHP+gKq6fu7m/Un+MN4psqZ0Qy/t0EM39NIOPXRDL+3QQzeszL7/u1lr7UJVPZzkJ0muSvJ4a+3lqno0yVZrbTPJf1bV/UkuJHkryUNLPGfWgG7opR166IZe2qGHbuilHXrohlWq1tqR/OKNjY22tbV1JL+b5aqqs621jWU9v3aOJ93Qa5nt6Ob4MnPoZebQw8yhl5lDj8N0M9YHVwMAAACwxiyJAAAAALAkAgAAAMCSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIAMXBJV1b1V9UpVbVfVI3s8fk1VPTN7/PmqOjn2ibJ+dEMv7dBDN/TSDj10Qy/t0EM3rMq+S6KquirJY0k+keT2JJ+qqtt3Hfa5JH9rrX0oydeTfG3sE2W96IZe2qGHbuilHXrohl7aoYduWKUhryS6K8l2a+3V1tq7SZ5OcmrXMaeSPDn7/tkk91RVjXearCHd0Es79NANvbRDD93QSzv00A0rM2RJdEOS1+Zun5vdt+cxrbULSd5O8oExTpC1pRt6aYceuqGXduihG3pphx66YWVOrPKXVdXpJKdnN9+pqpdW+fuP0AeT/PWoT2KFPjz2E2pnEnQznil1k4zczoS7SabVjpkznil1k5g5Y5pSO2bOeKbUTWLmjGlK7XR3M2RJ9HqSm+Zu3zi7b69jzlXViSTvS/Lm7idqrZ1JciZJqmqrtbbRc9LrZkrXmuxcb0bsJtHOUZ/HKsy6ScycQ5vStSbjz5ypdpNM63rNnPFM6VoTM2dMU7peM2c8U7rWxMwZ05Sud27mHNiQt5u9kOTWqrq5qq5O8mCSzV3HbCb5zOz7Tyb5eWut9Z4Ux4Ju6KUdeuiGXtqhh27opR166IaV2feVRK21C1X1cJKfJLkqyeOttZer6tEkW621zSTfTfL9qtpO8lZ2omXCdEMv7dBDN/TSDj10Qy/t0EM3rFId1XKxqk7PXup27E3pWpPlX++U/p6udX2e/0oypWtNlnu9/pbHl5kznilda2LmjGlK12vmjGdK15qYOWOa0vUe5lqPbEkEAAAAwJVjyGcSAQAAAHDMLX1JVFX3VtUrVbVdVY/s8fg1VfXM7PHnq+rkss9pWQZc60NVdb6qfjP7+vxRnOcYqurxqvrL5f7LxNrxjdnf4sWquuOAzz+ZbpLptLPsbmbPMZl2ptJNYuaMbSrtmDnjmko3iZkzJt0sPG7mHIB2Fh43cwbSzcLjfd201pb2lZ0P1fpTkluSXJ3kt0lu33XMF5N8e/b9g0meWeY5HfG1PpTkm0d9riNd70eT3JHkpcs8fl+SHyepJHcneV432llmN1NrZ0rdLLudKXUztXbMHN1cie3oRjdmjnZW2Y5udHPQbpb9SqK7kmy31l5trb2b5Okkp3YdcyrJk7Pvn01yT1XVks9rGYZc67HRWvtldj41/3JOJfle2/GrJO+vqusHPv2Uukkm1M6Su0mm1c5kuknMnJFNph0zZ1ST6SYxc0akm0VmznDaWWTmDKObRV3dLHtJdEOS1+Zun5vdt+cxrbULSd5O8oEln9cyDLnWJHlg9lKvZ6vqptWc2pEY+vfo/dnj0k2inXmH6Wbozx+XdnSzyMwZTjsXmTnD6WaRmTOMbhaZOcNpZ5GZM4xuFnV1s++SaBXvrZ2QHyY52Vr7SJKf5uK29rh6RDujmVI7uhnPlLpJtDOmKbWjm/FMqZtEO2PRzRzdHIh25mhnsKl1c2BDXkn0RJJ7/8Xjn0hy6+zrdJJvzT32epL5zdyNs/uy1zFVdSLJ+5K8OeC8rjT7Xmtr7c3W2juzm99JcueKzu0ovJ7kbC62s9e//eXamVI3iXbmHaab//v5qbSjm0VmznDaucjMGU43i8ycYXSzyMwZTjuLzJxhdLNoyL/9JfZdEh3yfW4vJLm1qm6uqquz8yFYm7t+fjPJZ2bffzLJz1vb+ZSlNbPvte56/9/9Sf6wwvNbtc3svCf0rST/luTt1tobu465XDtT6ibRzrzDdJNMqx3dLDJzhtPORWbOcLpZZOYMo5tFZs5w2llk5gyjm0WbST49e5XZ3dm7m0u1YZ+afTKX/8Ts55L8x9ztnyXZmLt9X5I/ZudTxr88u+/RJPfPvn9vkh8k2U7y6yS3DDmnK/FrwLV+NcnL2fmU9V8kue2oz/kQ1/pUkjeS/CM77238XJIvJPnC7PFK8liSPyf53/kmhrQzpW6m1M6yu5laO1PpZhXtTKmbKbVj5ujmSm1HN7oxc7SzynZ0M/lu/pTkd3t1s9dXzX74X6qqk0mea639+x6PPZfkv1tr/zO7/bMk/9Va29rj2NPZeelbrr322jtvu+22fX836+fs2bN/ba1dl2iH4XRDr7Hb0c00mDn0MnPoYebQy8yhx3w3B3VihN8/+H1urbUzSc4kycbGRtvaumTWcQxU1Z8HHqod/kk39Bq7Hd1Mg5lDLzOHHmYOvcwcehygm0sM+eDq/fS9zw20Qx/d0Es79NANvbRDD93QSzuMYt9XElXVU0k+luSDVXUuyVeSvCdJWmvfTvKj7LzvbzvJ35N8dlkny3rRDj10Qy/t0EM39NIOPXRDL+2wKvsuiVprn9rn8ZbkS6OdEceGduihG3pphx66oZd26KEbemmHVRnj7WYAAAAArDlLIgAAAAAsiQAAAACwJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAZOCSqKrurapXqmq7qh7Z4/GHqup8Vf1m9vX58U+VdaMbemmHHrqhl3booRt6aYceumFVTux3QFVdleSxJB9Pci7JC1W12Vr7/a5Dn2mtPbyEc2QN6YZe2qGHbuilHXrohl7aoYduWKUhryS6K8l2a+3V1tq7SZ5Ocmq5p8UxoBt6aYceuqGXduihG3pphx66YWWGLIluSPLa3O1zs/t2e6CqXqyqZ6vqpr2eqKpOV9VWVW2dP3++43RZI6N1k2hnYswceuiGXtqhh27opR166IaVGeuDq3+Y5GRr7SNJfprkyb0Oaq2daa1ttNY2rrvuupF+NWtsUDeJdriEmUMP3dBLO/TQDb20Qw/dMIohS6LXk8xvIW+c3fdPrbU3W2vvzG5+J8md45wea0w39NIOPXRDL+3QQzf00g49dMPKDFkSvZDk1qq6uaquTvJgks35A6rq+rmb9yf5w3inyJrSDb20Qw/d0Es79NANvbRDD92wMvv+72attQtV9XCSnyS5KsnjrbWXq+rRJFuttc0k/1lV9ye5kOStJA8t8ZxZA7qhl3booRt6aYceuqGXduihG1apWmtH8os3Njba1tbWkfxulquqzrbWNpb1/No5nnRDr2W2o5vjy8yhl5lDDzOHXmYOPQ7TzVgfXA0AAADAGrMkAgAAAMCSCAAAAABLIgAAAABiSQQAAABALIkAAAAAiCURAAAAALEkAgAAACCWRAAAAADEkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAAsSQCAAAAIJZEAAAAAMSSCAAAAIBYEgEAAAAQSyIAAAAAYkkEAAAAQCyJAAAAAIglEQAAAACxJAIAAAAglkQAAAAAxJIIAAAAgFgSAQAAABBLIgAAAAAycElUVfdW1StVtV1Vj+zx+DVV9czs8eer6uTYJ8r60Q29tEMP3dBLO/TQDb20Qw/dsCr7Lomq6qokjyX5RJLbk3yqqm7fddjnkvyttfahJF9P8rWxT5T1oht6aYceuqGXduihG3pphx66YZWGvJLoriTbrbVXW2vvJnk6yaldx5xK8uTs+2eT3FNVNd5psoZ0Qy/t0EM39NIOPXRDL+3QQzeszJAl0Q1JXpu7fW52357HtNYuJHk7yQfGOEHWlm7opR166IZe2qGHbuilHXrohpU5scpfVlWnk5ye3Xynql5a5e8/Qh9M8tejPokV+vDYT6idSdDNeKbUTTJyOxPuJplWO2bOeKbUTWLmjGlK7Zg545lSN4mZM6YptdPdzZAl0etJbpq7fePsvr2OOVdVJ5K8L8mbu5+otXYmyZkkqaqt1tpGz0mvmylda7JzvRmxm0Q7R30eqzDrJjFzDm1K15qMP3Om2k0yres1c8YzpWtNzJwxTel6zZzxTOlaEzNnTFO63rmZc2BD3m72QpJbq+rmqro6yYNJNncds5nkM7PvP5nk56211ntSHAu6oZd26KEbemmHHrqhl3booRtWZt9XErXWLlTVw0l+kuSqJI+31l6uqkeTbLXWNpN8N8n3q2o7yVvZiZYJ0w29tEMP3dBLO/TQDb20Qw/dsEp1VMvFqjo9e6nbsTela02Wf71T+nu61vV5/ivJlK41We71+lseX2bOeKZ0rYmZM6YpXa+ZM54pXWti5oxpStd7mGs9siURAAAAAFeOIZ9JBAAAAMAxt/QlUVXdW1WvVNV2VT2yx+PXVNUzs8efr6qTyz6nZRlwrQ9V1fmq+s3s6/NHcZ5jqKrHq+ovl/svE2vHN2Z/ixer6o4DPv9kukmm086yu5k9x2TamUo3iZkztqm0Y+aMayrdJGbOmHSz8LiZcwDaWXjczBlINwuP93XTWlvaV3Y+VOtPSW5JcnWS3ya5fdcxX0zy7dn3DyZ5ZpnndMTX+lCSbx71uY50vR9NckeSly7z+H1Jfpykktyd5HndaGeZ3UytnSl1s+x2ptTN1Noxc3RzJbajG92YOdpZZTu60c1Bu1n2K4nuSrLdWnu1tfZukqeTnNp1zKkkT86+fzbJPVVVSz6vZRhyrcdGa+2X2fnU/Ms5leR7bcevkry/qq4f+PRT6iaZUDtL7iaZVjuT6SYxc0Y2mXbMnFFNppvEzBmRbhaZOcNpZ5GZM4xuFnV1s+wl0Q1JXpu7fW52357HtNYuJHk7yQeWfF7LMORak+SB2Uu9nq2qm1Zzakdi6N+j92ePSzeJduYdppuhP39c2tHNIjNnOO1cZOYMp5tFZs4wullk5gynnUVmzjC6WdTVjQ+uXq0fJjnZWvtIkp/m4rYW9qMdeuiGXtqhh27ooRt6aYceutnHspdEryeZ38zdOLtvz2Oq6kSS9yV5c8nntQz7Xmtr7c3W2juzm99JcueKzu0oDPm3P8zPHpduEu3MO0w3Q3/+uLSjm0VmznDaucjMGU43i8ycYXSzyMwZTjuLzJxhdLOoq5tlL4leSHJrVd1cVVdn50OwNncds5nkM7PvP5nk5232KUtrZt9r3fX+v/uT/GGF57dqm0k+PftE9buTvN1ae2Pgz06pm0Q78w7TTTKtdnSzyMwZTjsXmTnD6WaRmTOMbhaZOcNpZ5GZM4xuFvV105b/idv3Jfljdj5l/Muz+x5Ncv/s+/cm+UGS7SS/TnLLss/pCK/1q0lezs6nrP8iyW1Hfc6HuNankryR5B/ZeW/j55J8IckXZo9Xksdmf4vfJdnQjXaW3c3U2plKN6toZ0rdTKkdM0c3V2o7utGNmaOdVbajG90cpJua/TAAAAAAE+aDqwEAAACwJAIAAADAkggAAACAWBIBAAAAEEsiAAAAAGJJBAAAAEAsiQAAAACIJREAAAAASf4/ldg4Vkp5A/4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x576 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(5, 8, figsize=(20, 8))\n",
    "for i in range(len(axs)):\n",
    "    for j in range(len(axs[i])):\n",
    "      axs[i, j].imshow(X_train[50 * i + j].reshape((28, 28)), cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dABLbJ5vVzdb"
   },
   "source": [
    "## Entrenar nuestro clasificador de caracteres\n",
    "Es hora de entrenar y evaluar el clasificador de caracteres que luego seráá empleado por la clase TextRecognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "-ZtAqFYa5UdJ",
    "outputId": "35e2b546-d7f5-4ff6-bb5f-5504c3fd0f0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Learn to predict the indices\n",
    "print(\"--> Training classifier\")\n",
    "clf = NearestCentroid()  # TODO Usa aquí el clasificador que desees\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"--> Evaluating classifier\")\n",
    "pred = clf.predict(X_train)\n",
    "accuracy = (y_train == pred).sum() / len(pred)\n",
    "print(\"----> Training accuracy: {:.2f}%\".format(100 * accuracy))\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "accuracy = (y_test == pred).sum() / len(pred)\n",
    "print(\"----> Test Accuracy: {:.2f}%\".format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "js9RR0Nxs8q3"
   },
   "source": [
    "## Detección y reconocimiento de texto con el clasificador de caracteres\n",
    "\n",
    "La clase TextRecognezer espera como parámetros un clasificador de caracteres y un mapping que transforme las salidas de enteros a letras.\n",
    "\n",
    "Para hacer el reconocimiento completo de texto podríamos emplear el método **detect_image_text**, pero vamos a ejecutar paso a paso cada una de sus instrucciones para vber cómo funciona este detector de caracteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "W5DMkhqUs8q6",
    "outputId": "0a7f4b71-5678-4b87-8e02-b65cd8e9c2dd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the input image\n",
    "tr = TextRecognizer(clf, labels)\n",
    "image_path = os.path.join(resources_dir, 'EJEMPLO_PRACTICA6.JPG')\n",
    "\n",
    "# Read the input image\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Cannot find file \\\"{}\\\"\".format(image_path))\n",
    "assert img.shape[0] > img.shape[1], \"Error: The image should be a portrait paper.\"\n",
    "\n",
    "# Resize image to a fixed processing size\n",
    "IMG_WIDTH = 2500.0  # pixels\n",
    "scale_factor = IMG_WIDTH / img.shape[1]\n",
    "img = cv2.resize(img, (int(scale_factor * img.shape[1]), int(scale_factor * img.shape[0])))\n",
    "\n",
    "# Blur image to remove some noise\n",
    "blur = cv2.GaussianBlur(img, (5, 3), 1)\n",
    "plt.imshow(blur, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUxjw5Exs8rr"
   },
   "source": [
    "## Binarización de la imagen de entrada\n",
    "Hasta el momento lo que hemos hecho ha sido:\n",
    "\n",
    "* Leer la imagen de entrada\n",
    "* Convertirla a escala de grises\n",
    "* Redimensionarla para que los caracteres tenga un tamaño considerable\n",
    "* Difuminarla un poco para eliminar ruido que pueda afectar a la detección.\n",
    "\n",
    "Para poder proceder a la detección de los caracteres tenemos que saber de forma inequívoca donde hay un caracter y donde no. Con este objetivo convertimos la image a una imagen binaria, donde los píxeles solo pueden tomar dos valores 0 y 255. Consideraremos que todos los píxeles con valor 255 son candidatos a estar en una letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ESzSbp2As8rt",
    "outputId": "99b51cd3-28ba-44ed-b1f0-5d8b857c962b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88d23678b2b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Binarize image using the smart Otsu binarization method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbin_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blur' is not defined"
     ]
    }
   ],
   "source": [
    "# Binarize image using the smart Otsu binarization method\n",
    "bin_img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "plt.imshow(bin_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b1Et6Woas8ry",
    "outputId": "465cd1fa-4e43-4e00-bb35-49ffa42863d7",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f56291379e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Detect individual chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchar_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "# Detect individual chars\n",
    "char_boxes, detected_chars = tr.detect_chars(bin_img, tr.predict_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zZ6RUa-Ss8r4",
    "outputId": "a75fb659-4065-40ff-8518-f7be4b63639d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5be98887c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Detect words based on the detected chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "# Detect words based on the detected chars\n",
    "word_boxes, detected_words = tr.detect_words(bin_img, char_boxes, detected_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IHwJ52V2s8r8",
    "outputId": "2c3939a0-4275-4deb-83f7-4fb08bd25f73"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-853d7cea80b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Detect text lines based on the detected words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# convert from the lines dictionary format to a string with all the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetected_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "# Detect text lines based on the detected words\n",
    "lines = tr.detect_lines(bin_img, word_boxes, detected_words)\n",
    "\n",
    "# convert from the lines dictionary format to a string with all the text\n",
    "detected_text = ''\n",
    "line_words = []\n",
    "for l in lines:\n",
    "    line_words.append(l['words'])\n",
    "    detected_text += functools.reduce(lambda a, b: a + ' ' + b, l['words']) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Zhn1b7W0gGB"
   },
   "source": [
    "## Evaluación empírica del resultado\n",
    "Para evaluar el resultado obtenido en el reconocimiento del texto te proporcionamos una funcióón que te indica el ratio de texto correctamente detectado. Esta funcióón te serviráá para poder comparar los resultados de distintos clasificadores, bases de datos o características que creas que pueden mejorar el rendimiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgCZl6fMs8qu"
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# ################################# Evaluation #################################\n",
    "# ##############################################################################\n",
    "\n",
    "def evaluate_text_detection(line_words):\n",
    "    \"\"\"\n",
    "    Evaluates the detection of the text in images.\n",
    "    :param line_words: A list of lists with the line words.\n",
    "    :return: A ratio of detected characters. 0 is the worse results, 1 means perfect detection.\n",
    "    \"\"\"\n",
    "    expected_lines = [\n",
    "        \"RECONOCIMIENTO DE FORMAS 2019/20\",\n",
    "        \"TRATAMIENTO DE UN PROBLEMA REAL DE RECONOCIMIENTO DE TEXTO\",\n",
    "        \"EL OBJETIVO DE ESTA ULTIMA PARTE DE LA PRACTICA ES ENFRENTARSE A UN PROBLEMA\",\n",
    "        \"REAL DE RECONOCIMIENTO DE FORMAS COMO ES LA LECTURA AUTOMATICA DE TEXTO\",\n",
    "        \"ESCANEADO EN ESTA PRACTICA SE PROPORCIONA UN METODO DE EVALUACION QUE PERMITE\",\n",
    "        \"CONOCER EL RATIO DE TEXTO CORRECTAMENTE DETECTADO SE DEBE TRATAR DE OBTENER LOS\",\n",
    "        \"MEJORES RESULTADOS\",\n",
    "        \"1 INTRODUCCION\",\n",
    "        \"EN ESTA PRACTICA SE DESARROLLARA UN CODIGO CAPAZ DE RECONOCER EL TEXTO DE ESTA\",\n",
    "        \"PRIMERA HOJA DEL ENUNCIADO COMO EN MUCHAS SITUACIONES DE LA VIDA REAL EL\",\n",
    "        \"ALUMNO DESCONOCERA LAS IMAGENES QUE SE EMPLEARAN PARA LA EVALUACION POR LO QUE\",\n",
    "        \"SE LE RECOMIENDA IMPRIMIR ESTA PRIMERA HOJA DEL ENUNCIADO Y LA FOTOGRAFIARLA\",\n",
    "        \"REPETIDAS VECES DE TAL MODO QUE PUEDA OBTENER SU PROPIO CONJUNTO DE VALIDACION\",\n",
    "        \"LO MAS COMPLETO POSIBLE\",\n",
    "        \"SE CREARA UNA COMPETICION EN EL AULA VITUAL DONDE EL ALUMNO DEBE PUBLICAR EL\",\n",
    "        \"RESULTADO DE PROCESAR LA IMAGEN EJEMPLO_PRACTICA6JPG QUE SE LE PROPORCIONA\",\n",
    "        \"LA POSICION EN ESTE CONCURSO SERA UNO DE LOS CRITERIOS DE CALIFICACION DE LA\",\n",
    "        \"PRACTICA\",\n",
    "        \"2 ALCANCE\",\n",
    "        \"EN EL FICHERO ESQUELETO6IPYNB QUE SE PUEDE ENCONTRAR EN EL AULA VIRTUAL SE\",\n",
    "        \"PROPORCIONA CODIGO PARA AYUDAR EN LAS DISTINTAS FASES DEL PROCESO DE\",\n",
    "        \"RECONOCIMIENTO ESTE CODIGO LEE UNA IMAGEN DE DISCO Y APLICA DIVERSOS\",\n",
    "        \"PROCEDIMIENTOS PARA LEER EL TEXTO CON AYUDA DE UN RECONOCEDOR DE CARACTERES LA\",\n",
    "        \"IMAGEN DE ENTRADA DEBE SER VERTICAL NITIDA Y CON UNA ILUMINACION HOMOGENEA\",\n",
    "        \"COMO EL EJEMPLO QUE SE PROPORCIONA EN EL FICHERO EJEMPLO_PRACTICA6JPG NO SE\",\n",
    "        \"ESPERA QUE LA PRACTICA PUEDA RECONOCER IMAGENES EN OTRAS CONDICIONES\",\n",
    "        \"3 TAREAS A REALIZAR\",\n",
    "        \"LA PRACTICA ESTA ABIERTA PARA QUE EL ALUMNO REALICE CUALQUIER MODIFICACION QUE\",\n",
    "        \"PUEDA MEJORAR EL RESULTADO DE LA DETECCION DEBE UTILIZAR LO APRENDIDO EN LA\",\n",
    "        \"ASIGNATURA PARA DIAGNOSTICAR EN CADA MOMENTO CUAL ES EL MOTIVO POR EL QUE EL\",\n",
    "        \"RECONOCIMIENTO NO ESTA FUNCIONANDO Y PROCEDER A SOLUCIONARLO SIN EMBARGO AQUI\",\n",
    "        \"PROPORCIONAMOS ALGUNAS IDEAS:\",\n",
    "        \"¿SE ESTA EMPLEANDO EL CLASIFICADOR MAS ADECUADO?\",\n",
    "        \"¿ESTAN BIEN AJUSTADOS SUS PARAMETROS?\",\n",
    "        \"¿ES EL CONJUNTO DE ENTRENAMIENTO REPRESENTATIVO DEL PROBLEMA AL QUE SE\",\n",
    "        \"ENFRENTA EL CLASIFICADOR EN UNA IMAGEN REAL?\",\n",
    "        \"¿ESTA EL PROBLEMA BALANCEADO? SI NO ES ASI ¿TIENE SENTIDO ENTRENAR EN UN\",\n",
    "        \"PROBLEMA DESBALANCEADO?\",\n",
    "        \"¿SON TODAS LAS CARACTERISTICAS NECESARIAS? ¿ES NECESARIO HACER UNA\",\n",
    "        \"SELECCION O UNA REDUCCION DE LA DIMENSIONALIDAD?\",\n",
    "        \"4 DOCUMENTACION A PRESENTAR\",\n",
    "    ]\n",
    "\n",
    "    def line_match_score(correct_line, detected_line):\n",
    "        correct_line_chars = ''.join(correct_line).replace(' ', '')\n",
    "        detected_line = ''.join(detected_line).replace(' ', '')\n",
    "        correct_chars, correct_count = np.unique(list(correct_line_chars), return_counts=True)\n",
    "        detected_chars, detected_count = np.unique(list(detected_line), return_counts=True)\n",
    "        errors = 0\n",
    "        for i in range(len(correct_chars)):\n",
    "            n_detected = detected_count[np.argwhere(detected_chars == correct_chars[i])]\n",
    "            errors += correct_count[i] if n_detected.size == 0 else abs(n_detected[0, 0] - correct_count[i])\n",
    "        return 1 - errors / np.sum(correct_count)\n",
    "\n",
    "    score_mat = np.zeros((len(expected_lines), len(line_words)))\n",
    "    for i in range(len(expected_lines)):\n",
    "        for j in range(len(line_words)):\n",
    "            score = line_match_score(expected_lines[i], line_words[j])\n",
    "            score_mat[i, j] = score\n",
    "\n",
    "    # Take for each correct line the score of the line that best fits\n",
    "    line_score = np.max(score_mat, axis=1)\n",
    "    # print(\"Detection score for each correct line: \", line_score)\n",
    "    # Assign to each line a weight proportional to its number of letters\n",
    "    line_weight = np.array([len(''.join(l).replace(' ', '')) for l in expected_lines])\n",
    "    line_weight = line_weight / line_weight.sum()\n",
    "    return (line_weight * line_score).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGGBa8-M1RES"
   },
   "source": [
    "Por último mostramos el texto detectado y el porcentaje de tecto correctamente reconocido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "OZLHB1X4vBy1",
    "outputId": "95e588d2-6cf5-4e62-cbdc-e40d49868a33"
   },
   "outputs": [],
   "source": [
    "print(\"--> Result:\")\n",
    "print(\"********************************************************************************\")\n",
    "print(detected_text)\n",
    "print(\"********************************************************************************\")\n",
    "print(\"Recognition percentage: {:.2f}%\".format(evaluate_text_detection(line_words) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
