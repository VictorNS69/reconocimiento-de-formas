{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 4 Reconocimiento de Formas: Clasificador Bayesiano Paramétrico\n",
    "\n",
    "* **Alumno 1**: Víctor Nieves Sánchez\n",
    "* **Alumno 2**: Javier Barragán Haro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.covariance import ShrunkCovariance, empirical_covariance\n",
    "from sklearn import preprocessing\n",
    "from abc import abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "\n",
    "class ClassifBayesianoParametrico(Classifier):\n",
    "    def __init__(self, share_covs=False, shrinkage=0.0):\n",
    "        \"\"\"Constructor de la clase\n",
    "        share_covs: Indica si la matriz de covarianzas va a ser compartida entre las distintas clases.\n",
    "        shrinkage: Parámetro que determina la diagonalidad de la matriz de covarianzas. \n",
    "        Ver sklearn.covariance.ShrunkCovariance\n",
    "        \"\"\"\n",
    "        assert 0 <= shrinkage <= 1\n",
    "        self.labels = None\n",
    "        self.ln_apriories = None\n",
    "        self.means = None\n",
    "        self.ln_determinants = None\n",
    "        self.inv_covs = None\n",
    "        self.share_covs = share_covs\n",
    "        self.shrinkage = shrinkage\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        # Aseguramos que las etiquetas son numeros tal que: [0, 1, ..., N]\n",
    "        y = pd.factorize(y)[0]\n",
    "        # Preprocesamos los datos de entrada\n",
    "        self.scaler = preprocessing.scale(X)      \n",
    "        self.labels = y\n",
    "\n",
    "        # Contar cuantos ejemplos hay de cada etiqueta\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        # Usando el contador de ejemplos de cada etiqueta, calcular el logaritmo neperiano de las \n",
    "        # probabilidades a-priori\n",
    "        self.ln_apriories = np.array([np.log((counts[i]/np.sum(counts))) for i in unique])\n",
    "        # Calcular para los ejemplos de cada clase, la media de cada una de sus características (centroide)\n",
    "        self.means = np.array([np.mean(X[y==i], axis=0) for i in unique])\n",
    "        print(self.means)\n",
    "        \n",
    "        if self.share_covs:\n",
    "            # Restamos al dato de cada clase su centroide\n",
    "            newX = np.array([X[y==i] - self.means[i] for i in unique])\n",
    "            print(newX)\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            covs = empirical_covariance(self.scaler)\n",
    "            print(\"COV1--->\", covs)\n",
    "            covs = ShrunkCovariance().fit(covs,self.shrinkage)\n",
    "            print(\"COV--->\", covs)\n",
    "            # La reproducimos tantas veces como número de clases\n",
    "            for i in unique:\n",
    "                covs = empirical_covariance(covs)\n",
    "                covs = ShrunkCovariance.fit(covs, self.shrinkage) \n",
    "        else:\n",
    "            # Calcula la matriz de covarianzas empleando la clase ShrunkCovariance de sklearn\n",
    "            covs = ShrunkCovariance.fit(X,y)\n",
    "        print(\"COV--->\", covs)\n",
    "        # Para cada una de las clases, calcular el logaritmo neperiano de su matriz de covarianzas \n",
    "        # (puedes emplear compresión de listas o la función map)\n",
    "        self.ln_determinants = np.log(list(map(np.linalg.det, covs)))\n",
    "        # Para cada una de las clases, calcular la inversa de su matriz de covarianzas \n",
    "        # (puedes emplear compresión de listas o la función map)\n",
    "        self.inv_covs = np.array(list(map(np.linalg.pinv,covs)))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        \n",
    "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
    "\n",
    "        # Preprocesamos nuestros datos\n",
    "        X = preprocessing.scale(X)\n",
    "\n",
    "        # Resta la media de cada clase a cada ejemplo en X\n",
    "        X_mean0 = self.means[:,np.newaxis,:] - X       \n",
    "\n",
    "        # Calcula el logaritmo de la función de decisión gausiana\n",
    "        # Transparencias de Métodos paramétricos de clasificación: página 14:\n",
    "        # -(1/2)ln|Sigma_i| - (1/2)*(x- mu_i)^T Sigma_i^-1 (x- mu_i) + lnP(alpha_i)\n",
    "        return -0.5 * self.ln_determinants[:, np.newaxis] \\\n",
    "            - 0.5 * np.array([np.sum((X_mean0[i] @ self.inv_covs[i]) \n",
    "                                     * X_mean0[i], axis=1) for i in np.unique(y)]) \\\n",
    "            + self.ln_apriories[:, np.newaxis]        \n",
    "\n",
    "\n",
    "    def pred_label(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(X, axis = 0)\n",
    "\n",
    "    def num_aciertos(self, X): \n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(X[i] == self.labels[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "\n",
    "        return number, (number / len(X)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "## Iris Dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "outputId": "83a2381b-a4b1-42f2-e86d-1b0519b1e634",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.006 3.428 1.462 0.246]\n",
      " [5.936 2.77  4.26  1.326]\n",
      " [6.588 2.974 5.552 2.026]]\n",
      "[[[ 0.094  0.072 -0.062 -0.046]\n",
      "  [-0.106 -0.428 -0.062 -0.046]\n",
      "  [-0.306 -0.228 -0.162 -0.046]\n",
      "  [-0.406 -0.328  0.038 -0.046]\n",
      "  [-0.006  0.172 -0.062 -0.046]\n",
      "  [ 0.394  0.472  0.238  0.154]\n",
      "  [-0.406 -0.028 -0.062  0.054]\n",
      "  [-0.006 -0.028  0.038 -0.046]\n",
      "  [-0.606 -0.528 -0.062 -0.046]\n",
      "  [-0.106 -0.328  0.038 -0.146]\n",
      "  [ 0.394  0.272  0.038 -0.046]\n",
      "  [-0.206 -0.028  0.138 -0.046]\n",
      "  [-0.206 -0.428 -0.062 -0.146]\n",
      "  [-0.706 -0.428 -0.362 -0.146]\n",
      "  [ 0.794  0.572 -0.262 -0.046]\n",
      "  [ 0.694  0.972  0.038  0.154]\n",
      "  [ 0.394  0.472 -0.162  0.154]\n",
      "  [ 0.094  0.072 -0.062  0.054]\n",
      "  [ 0.694  0.372  0.238  0.054]\n",
      "  [ 0.094  0.372  0.038  0.054]\n",
      "  [ 0.394 -0.028  0.238 -0.046]\n",
      "  [ 0.094  0.272  0.038  0.154]\n",
      "  [-0.406  0.172 -0.462 -0.046]\n",
      "  [ 0.094 -0.128  0.238  0.254]\n",
      "  [-0.206 -0.028  0.438 -0.046]\n",
      "  [-0.006 -0.428  0.138 -0.046]\n",
      "  [-0.006 -0.028  0.138  0.154]\n",
      "  [ 0.194  0.072  0.038 -0.046]\n",
      "  [ 0.194 -0.028 -0.062 -0.046]\n",
      "  [-0.306 -0.228  0.138 -0.046]\n",
      "  [-0.206 -0.328  0.138 -0.046]\n",
      "  [ 0.394 -0.028  0.038  0.154]\n",
      "  [ 0.194  0.672  0.038 -0.146]\n",
      "  [ 0.494  0.772 -0.062 -0.046]\n",
      "  [-0.106 -0.328  0.038 -0.046]\n",
      "  [-0.006 -0.228 -0.262 -0.046]\n",
      "  [ 0.494  0.072 -0.162 -0.046]\n",
      "  [-0.106  0.172 -0.062 -0.146]\n",
      "  [-0.606 -0.428 -0.162 -0.046]\n",
      "  [ 0.094 -0.028  0.038 -0.046]\n",
      "  [-0.006  0.072 -0.162  0.054]\n",
      "  [-0.506 -1.128 -0.162  0.054]\n",
      "  [-0.606 -0.228 -0.162 -0.046]\n",
      "  [-0.006  0.072  0.138  0.354]\n",
      "  [ 0.094  0.372  0.438  0.154]\n",
      "  [-0.206 -0.428 -0.062  0.054]\n",
      "  [ 0.094  0.372  0.138 -0.046]\n",
      "  [-0.406 -0.228 -0.062 -0.046]\n",
      "  [ 0.294  0.272  0.038 -0.046]\n",
      "  [-0.006 -0.128 -0.062 -0.046]]\n",
      "\n",
      " [[ 1.064  0.43   0.44   0.074]\n",
      "  [ 0.464  0.43   0.24   0.174]\n",
      "  [ 0.964  0.33   0.64   0.174]\n",
      "  [-0.436 -0.47  -0.26  -0.026]\n",
      "  [ 0.564  0.03   0.34   0.174]\n",
      "  [-0.236  0.03   0.24  -0.026]\n",
      "  [ 0.364  0.53   0.44   0.274]\n",
      "  [-1.036 -0.37  -0.96  -0.326]\n",
      "  [ 0.664  0.13   0.34  -0.026]\n",
      "  [-0.736 -0.07  -0.36   0.074]\n",
      "  [-0.936 -0.77  -0.76  -0.326]\n",
      "  [-0.036  0.23  -0.06   0.174]\n",
      "  [ 0.064 -0.57  -0.26  -0.326]\n",
      "  [ 0.164  0.13   0.44   0.074]\n",
      "  [-0.336  0.13  -0.66  -0.026]\n",
      "  [ 0.764  0.33   0.14   0.074]\n",
      "  [-0.336  0.23   0.24   0.174]\n",
      "  [-0.136 -0.07  -0.16  -0.326]\n",
      "  [ 0.264 -0.57   0.24   0.174]\n",
      "  [-0.336 -0.27  -0.36  -0.226]\n",
      "  [-0.036  0.43   0.54   0.474]\n",
      "  [ 0.164  0.03  -0.26  -0.026]\n",
      "  [ 0.364 -0.27   0.64   0.174]\n",
      "  [ 0.164  0.03   0.44  -0.126]\n",
      "  [ 0.464  0.13   0.04  -0.026]\n",
      "  [ 0.664  0.23   0.14   0.074]\n",
      "  [ 0.864  0.03   0.54   0.074]\n",
      "  [ 0.764  0.23   0.74   0.374]\n",
      "  [ 0.064  0.13   0.24   0.174]\n",
      "  [-0.236 -0.17  -0.76  -0.326]\n",
      "  [-0.436 -0.37  -0.46  -0.226]\n",
      "  [-0.436 -0.37  -0.56  -0.326]\n",
      "  [-0.136 -0.07  -0.36  -0.126]\n",
      "  [ 0.064 -0.07   0.84   0.274]\n",
      "  [-0.536  0.23   0.24   0.174]\n",
      "  [ 0.064  0.63   0.24   0.274]\n",
      "  [ 0.764  0.33   0.44   0.174]\n",
      "  [ 0.364 -0.47   0.14  -0.026]\n",
      "  [-0.336  0.23  -0.16  -0.026]\n",
      "  [-0.436 -0.27  -0.26  -0.026]\n",
      "  [-0.436 -0.17   0.14  -0.126]\n",
      "  [ 0.164  0.23   0.34   0.074]\n",
      "  [-0.136 -0.17  -0.26  -0.126]\n",
      "  [-0.936 -0.47  -0.96  -0.326]\n",
      "  [-0.336 -0.07  -0.06  -0.026]\n",
      "  [-0.236  0.23  -0.06  -0.126]\n",
      "  [-0.236  0.13  -0.06  -0.026]\n",
      "  [ 0.264  0.13   0.04  -0.026]\n",
      "  [-0.836 -0.27  -1.26  -0.226]\n",
      "  [-0.236  0.03  -0.16  -0.026]]\n",
      "\n",
      " [[-0.288  0.326  0.448  0.474]\n",
      "  [-0.788 -0.274 -0.452 -0.126]\n",
      "  [ 0.512  0.026  0.348  0.074]\n",
      "  [-0.288 -0.074  0.048 -0.226]\n",
      "  [-0.088  0.026  0.248  0.174]\n",
      "  [ 1.012  0.026  1.048  0.074]\n",
      "  [-1.688 -0.474 -1.052 -0.326]\n",
      "  [ 0.712 -0.074  0.748 -0.226]\n",
      "  [ 0.112 -0.474  0.248 -0.226]\n",
      "  [ 0.612  0.626  0.548  0.474]\n",
      "  [-0.088  0.226 -0.452 -0.026]\n",
      "  [-0.188 -0.274 -0.252 -0.126]\n",
      "  [ 0.212  0.026 -0.052  0.074]\n",
      "  [-0.888 -0.474 -0.552 -0.026]\n",
      "  [-0.788 -0.174 -0.452  0.374]\n",
      "  [-0.188  0.226 -0.252  0.274]\n",
      "  [-0.088  0.026 -0.052 -0.226]\n",
      "  [ 1.112  0.826  1.148  0.174]\n",
      "  [ 1.112 -0.374  1.348  0.274]\n",
      "  [-0.588 -0.774 -0.552 -0.526]\n",
      "  [ 0.312  0.226  0.148  0.274]\n",
      "  [-0.988 -0.174 -0.652 -0.026]\n",
      "  [ 1.112 -0.174  1.148 -0.026]\n",
      "  [-0.288 -0.274 -0.652 -0.226]\n",
      "  [ 0.112  0.326  0.148  0.074]\n",
      "  [ 0.612  0.226  0.448 -0.226]\n",
      "  [-0.388 -0.174 -0.752 -0.226]\n",
      "  [-0.488  0.026 -0.652 -0.226]\n",
      "  [-0.188 -0.174  0.048  0.074]\n",
      "  [ 0.612  0.026  0.248 -0.426]\n",
      "  [ 0.812 -0.174  0.548 -0.126]\n",
      "  [ 1.312  0.826  0.848 -0.026]\n",
      "  [-0.188 -0.174  0.048  0.174]\n",
      "  [-0.288 -0.174 -0.452 -0.526]\n",
      "  [-0.488 -0.374  0.048 -0.626]\n",
      "  [ 1.112  0.026  0.548  0.274]\n",
      "  [-0.288  0.426  0.048  0.374]\n",
      "  [-0.188  0.126 -0.052 -0.226]\n",
      "  [-0.588  0.026 -0.752 -0.226]\n",
      "  [ 0.312  0.126 -0.152  0.074]\n",
      "  [ 0.112  0.126  0.048  0.374]\n",
      "  [ 0.312  0.126 -0.452  0.274]\n",
      "  [-0.788 -0.274 -0.452 -0.126]\n",
      "  [ 0.212  0.226  0.348  0.274]\n",
      "  [ 0.112  0.326  0.148  0.474]\n",
      "  [ 0.112  0.026 -0.352  0.274]\n",
      "  [-0.288 -0.474 -0.552 -0.126]\n",
      "  [-0.088  0.026 -0.352 -0.026]\n",
      "  [-0.388  0.426 -0.152  0.274]\n",
      "  [-0.688  0.026 -0.452 -0.226]]]\n",
      "COV1---> [[ 1.         -0.11756978  0.87175378  0.81794113]\n",
      " [-0.11756978  1.         -0.4284401  -0.36612593]\n",
      " [ 0.87175378 -0.4284401   1.          0.96286543]\n",
      " [ 0.81794113 -0.36612593  0.96286543  1.        ]]\n",
      "COV---> ShrunkCovariance(assume_centered=False, shrinkage=0.1, store_precision=True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-be22f3c82d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2. Entrenar el clasificador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mClassifBayes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifBayesianoParametrico\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mClassifBayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 3. Predecir empleando la base de datos de entrenamiento (X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-5a97591a7d8a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# La reproducimos tantas veces como número de clases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mcovs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempirical_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mcovs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShrunkCovariance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/victor/.local/lib/python3.7/site-packages/sklearn/covariance/empirical_covariance_.py\u001b[0m in \u001b[0;36mempirical_covariance\u001b[0;34m(X, assume_centered)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         warnings.warn(\"Only one sample available. \"\n\u001b[1;32m     76\u001b[0m                       \"You may want to reshape your data array\")\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "# 2. Entrenar el clasificador\n",
    "ClassifBayes = ClassifBayesianoParametrico(True)\n",
    "ClassifBayes.fit(X,y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = ClassifBayes.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = ClassifBayes.pred_label(predict_matrix)\n",
    "\n",
    "correct = ClassifBayes.num_aciertos(labels_matrix)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsniqwE-9fp-"
   },
   "source": [
    "## Wine dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Wine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "dbakRtC79fqA",
    "outputId": "f68024cd-71d7-4e9d-e5aa-78b5cd73c22e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7kPXX70NobZ"
   },
   "source": [
    "## Breast cancer dataset\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Breast cancer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "_54KE327_QEa",
    "outputId": "b43bf02b-fd87-4258-dab9-89d07b2a516a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "# print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "# print(\"y: \\n\" + str(y))\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFLkiTYnNobf"
   },
   "source": [
    "## MNIST Database (Modified National Institute of Standards and Technology database)\n",
    "MNIST es una base de datos de texto manuscrito, que se usa de forma clásica para entrenar sistemas de procesado de imágenes.\n",
    "\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqWv7YjfNobj",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "DU-b7qbbRwt4",
    "outputId": "b886fc33-4757-4097-9e96-a1518fabf3f1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 2. Entrenar el clasificador\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLQthMw5Nobo"
   },
   "source": [
    "## Isolet Dataset (Isolated Letter Speech Recognition)\n",
    "Carga, entrenamiento, predicción y evaluación en la base de datos de Isolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFj7GFS4Nobp",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "# print(\"X: \\n\" + str(X))\n",
    "# print(\"y: \\n\" + str(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "V7UXiUYwRzCv",
    "outputId": "c289aa8d-3260-425c-d1a4-262bba184070",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 2. Entrenar el clasificador\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_kQ7OJd9fqD"
   },
   "source": [
    "Resultados de los tres experimentos:\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   |  |  |\n",
    "| Wine   |  |  |\n",
    "| Cancer |  |  |\n",
    "| MNIST  |  |  |\n",
    "| Isolet |  |   |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Solucion4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
