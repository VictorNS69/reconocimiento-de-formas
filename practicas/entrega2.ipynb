{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 2 Reconocimiento de Formas: Clasificador de la distancia euclídea\n",
    "\n",
    "* **Alumno 1**: Javier Barragán Haro\n",
    "* **Alumno 2**: Victor Nieves Sanchez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class ClassifEuclid(Classifier):\n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase\"\"\"\n",
    "        self.labels = labels\n",
    "        self.centroids = []\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        self.centroids = np.array([np.mean(x[y==i], axis=0) for i in np.unique(y)])\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.linalg.norm(self.centroids[:, np.newaxis] - x, axis=2)\n",
    "\n",
    "    def pred_label(self, x):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmin(x,axis=0)\n",
    "\n",
    "    def num_aciertos(self, x, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        same_values = []\n",
    "        [same_values.append(x[i] == y[i]) for i in range(0, len(self.labels))]\n",
    "        number = same_values.count(True)\n",
    "\n",
    "        return number, (number / len(x)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RABsoBjy07XN"
   },
   "source": [
    "## MNIST Database (Modified National Institute of Standards and Technology database)\n",
    "MNIST es una base de datos de texto manuscrito, que se usa de forma clásica para entrenar sistemas de procesado de imágenes. En esta práctica debes tratar de predecir el dígito de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfO9Ch2e05jF"
   },
   "outputs": [],
   "source": [
    "# # Loading MNIST from Drive\n",
    "# from google.colab import drive\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# drive.mount('/content/gdrive')\n",
    "# drive_dir = '/content/gdrive/My Drive/Colab Notebooks/MNIST/'\n",
    "\n",
    "# # Isntall idx2numpy to read the data\n",
    "# !pip install idx2numpy \n",
    "# import idx2numpy\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the images\n",
    "# file = drive_dir + 'train-images-idx3-ubyte/data'\n",
    "# X = idx2numpy.convert_from_file(file)\n",
    "\n",
    "# # Reshape the data. Each pixel is considered as a feature. 28 x 28 = 784\n",
    "# X = X.reshape(X.shape[0], -1)\n",
    "# print(\"X: \\n\" + str(X))\n",
    "\n",
    "# # Load the labels\n",
    "# file = drive_dir + 'train-labels-idx1-ubyte/data'\n",
    "# y = idx2numpy.convert_from_file(file)\n",
    "\n",
    "# print(\"y: \\n\" + str(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "Vd2TXXXH1MJY",
    "outputId": "a5e51ce9-b59c-4ddc-bbca-227457f147f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y: \n",
      "['5' '0' '4' ... '5' '6' '8']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Cargamos MNIST desde internet ( https://www.openml.org/d/554 )\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000]\n",
    "print(\"X: \\n\" + str(X))\n",
    "print(\"y: \\n\" + str(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Nem5x_TI2eFq",
    "outputId": "1d7e8c2a-4e4a-4bb6-cda2-516afab18087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN9klEQVR4nO3df4xV9ZnH8c+zWP6QojBrOhKKSyEGg8ZON4gbl6w1hvojGhw1TSexoZE4/YNJaLIhNewf1WwwZBU2SzTNTKMWNl1qEzUgaQouoOzGhDgiKo5LdQ2mTEaowZEf/mCHefaPezBTnfu9w7nn3nOZ5/1Kbu6957nnnicnfDi/7pmvubsATH5/VXYDAJqDsANBEHYgCMIOBEHYgSAuaubCzIxT/0CDubuNN72uLbuZ3Wpmh8zsPTN7sJ7vAtBYlvc6u5lNkfRHSUslHZH0qqQudx9IzMOWHWiwRmzZF0t6z93fd/czkn4raVkd3weggeoJ+2xJfxrz/kg27S+YWbeZ9ZtZfx3LAlCnhp+gc/c+SX0Su/FAmerZsg9KmjPm/bezaQBaUD1hf1XSlWb2HTObKulHkrYV0xaAouXejXf3ETPrkbRD0hRJT7n724V1BqBQuS+95VoYx+xAwzXkRzUALhyEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBJF7yGZcGKZMmZKsX3rppQ1dfk9PT9XaxRdfnJx3wYIFyfrKlSuT9ccee6xqraurKznv559/nqyvW7cuWX/44YeT9TLUFXYzOyzppKSzkkbcfVERTQEoXhFb9pvc/aMCvgdAA3HMDgRRb9hd0k4ze83Musf7gJl1m1m/mfXXuSwAdah3N36Juw+a2bckvWhm/+Pue8d+wN37JPVJkpl5ncsDkFNdW3Z3H8yej0l6XtLiIpoCULzcYTezaWY2/dxrST+QdLCoxgAUq57d+HZJz5vZue/5D3f/QyFdTTJXXHFFsj516tRk/YYbbkjWlyxZUrU2Y8aM5Lz33HNPsl6mI0eOJOsbN25M1js7O6vWTp48mZz3jTfeSNZffvnlZL0V5Q67u78v6bsF9gKggbj0BgRB2IEgCDsQBGEHgiDsQBDm3rwftU3WX9B1dHQk67t3707WG32baasaHR1N1u+///5k/dSpU7mXPTQ0lKx//PHHyfqhQ4dyL7vR3N3Gm86WHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4Dp7Adra2pL1ffv2Jevz5s0rsp1C1ep9eHg4Wb/pppuq1s6cOZOcN+rvD+rFdXYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIIhmwtw/PjxZH316tXJ+h133JGsv/7668l6rT+pnHLgwIFkfenSpcn66dOnk/Wrr766am3VqlXJeVEstuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EAT3s7eASy65JFmvNbxwb29v1dqKFSuS8953333J+pYtW5J1tJ7c97Ob2VNmdszMDo6Z1mZmL5rZu9nzzCKbBVC8iezG/1rSrV+Z9qCkXe5+paRd2XsALaxm2N19r6Sv/h50maRN2etNku4quC8ABcv72/h2dz83WNaHktqrfdDMuiV151wOgILUfSOMu3vqxJu790nqkzhBB5Qp76W3o2Y2S5Ky52PFtQSgEfKGfZuk5dnr5ZK2FtMOgEapuRtvZlskfV/SZWZ2RNIvJK2T9DszWyHpA0k/bGSTk92JEyfqmv+TTz7JPe8DDzyQrD/zzDPJeq0x1tE6aobd3buqlG4uuBcADcTPZYEgCDsQBGEHgiDsQBCEHQiCW1wngWnTplWtvfDCC8l5b7zxxmT9tttuS9Z37tyZrKP5GLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4LgOvskN3/+/GR9//79yfrw8HCyvmfPnmS9v7+/au2JJ55IztvMf5uTCdfZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIrrMH19nZmaw//fTTyfr06dNzL3vNmjXJ+ubNm5P1oaGhZD0qrrMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBBcZ0fSNddck6xv2LAhWb/55vyD/fb29ibra9euTdYHBwdzL/tClvs6u5k9ZWbHzOzgmGkPmdmgmR3IHrcX2SyA4k1kN/7Xkm4dZ/q/untH9vh9sW0BKFrNsLv7XknHm9ALgAaq5wRdj5m9me3mz6z2ITPrNrN+M6v+x8gANFzesP9S0nxJHZKGJK2v9kF373P3Re6+KOeyABQgV9jd/ai7n3X3UUm/krS42LYAFC1X2M1s1pi3nZIOVvssgNZQ8zq7mW2R9H1Jl0k6KukX2fsOSS7psKSfunvNm4u5zj75zJgxI1m/8847q9Zq3StvNu7l4i/t3r07WV+6dGmyPllVu85+0QRm7Bpn8pN1dwSgqfi5LBAEYQeCIOxAEIQdCIKwA0FwiytK88UXXyTrF12Uvlg0MjKSrN9yyy1Vay+99FJy3gsZf0oaCI6wA0EQdiAIwg4EQdiBIAg7EARhB4KoedcbYrv22muT9XvvvTdZv+6666rWal1Hr2VgYCBZ37t3b13fP9mwZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILjOPsktWLAgWe/p6UnW77777mT98ssvP++eJurs2bPJ+tBQ+q+Xj46OFtnOBY8tOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwXX2C0Cta9ldXeMNtFtR6zr63Llz87RUiP7+/mR97dq1yfq2bduKbGfSq7llN7M5ZrbHzAbM7G0zW5VNbzOzF83s3ex5ZuPbBZDXRHbjRyT9o7svlPR3klaa2UJJD0ra5e5XStqVvQfQomqG3d2H3H1/9vqkpHckzZa0TNKm7GObJN3VqCYB1O+8jtnNbK6k70naJ6nd3c/9OPlDSe1V5umW1J2/RQBFmPDZeDP7pqRnJf3M3U+MrXlldMhxB2109z53X+Tui+rqFEBdJhR2M/uGKkH/jbs/l00+amazsvosScca0yKAItTcjTczk/SkpHfcfcOY0jZJyyWty563NqTDSaC9fdwjnC8tXLgwWX/88ceT9auuuuq8eyrKvn37kvVHH320am3r1vQ/GW5RLdZEjtn/XtKPJb1lZgeyaWtUCfnvzGyFpA8k/bAxLQIoQs2wu/t/Sxp3cHdJNxfbDoBG4eeyQBCEHQiCsANBEHYgCMIOBMEtrhPU1tZWtdbb25uct6OjI1mfN29erp6K8MorryTr69evT9Z37NiRrH/22Wfn3RMagy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5jr79ddfn6yvXr06WV+8eHHV2uzZs3P1VJRPP/20am3jxo3JeR955JFk/fTp07l6Quthyw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYS5zt7Z2VlXvR4DAwPJ+vbt25P1kZGRZD11z/nw8HByXsTBlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3T3/AbI6kzZLaJbmkPnf/NzN7SNIDkv6cfXSNu/++xnelFwagbu4+7qjLEwn7LEmz3H2/mU2X9Jqku1QZj/2Uuz820SYIO9B41cI+kfHZhyQNZa9Pmtk7ksr90ywAztt5HbOb2VxJ35O0L5vUY2ZvmtlTZjazyjzdZtZvZv11dQqgLjV347/8oNk3Jb0saa27P2dm7ZI+UuU4/p9V2dW/v8Z3sBsPNFjuY3ZJMrNvSNouaYe7bxinPlfSdne/psb3EHagwaqFveZuvJmZpCclvTM26NmJu3M6JR2st0kAjTORs/FLJP2XpLckjWaT10jqktShym78YUk/zU7mpb6LLTvQYHXtxheFsAONl3s3HsDkQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii2UM2fyTpgzHvL8umtaJW7a1V+5LoLa8ie/ubaoWm3s/+tYWb9bv7otIaSGjV3lq1L4ne8mpWb+zGA0EQdiCIssPeV/LyU1q1t1btS6K3vJrSW6nH7ACap+wtO4AmIexAEKWE3cxuNbNDZvaemT1YRg/VmNlhM3vLzA6UPT5dNobeMTM7OGZam5m9aGbvZs/jjrFXUm8Pmdlgtu4OmNntJfU2x8z2mNmAmb1tZquy6aWuu0RfTVlvTT9mN7Mpkv4oaamkI5JeldTl7gNNbaQKMzssaZG7l/4DDDP7B0mnJG0+N7SWmf2LpOPuvi77j3Kmu/+8RXp7SOc5jHeDeqs2zPhPVOK6K3L48zzK2LIvlvSeu7/v7mck/VbSshL6aHnuvlfS8a9MXiZpU/Z6kyr/WJquSm8twd2H3H1/9vqkpHPDjJe67hJ9NUUZYZ8t6U9j3h9Ra4337pJ2mtlrZtZddjPjaB8zzNaHktrLbGYcNYfxbqavDDPeMusuz/Dn9eIE3dctcfe/lXSbpJXZ7mpL8soxWCtdO/2lpPmqjAE4JGl9mc1kw4w/K+ln7n5ibK3MdTdOX01Zb2WEfVDSnDHvv51NawnuPpg9H5P0vCqHHa3k6LkRdLPnYyX38yV3P+ruZ919VNKvVOK6y4YZf1bSb9z9uWxy6etuvL6atd7KCPurkq40s++Y2VRJP5K0rYQ+vsbMpmUnTmRm0yT9QK03FPU2Scuz18slbS2xl7/QKsN4VxtmXCWvu9KHP3f3pj8k3a7KGfn/lfRPZfRQpa95kt7IHm+X3ZukLars1v2fKuc2Vkj6a0m7JL0r6T8ltbVQb/+uytDeb6oSrFkl9bZElV30NyUdyB63l73uEn01Zb3xc1kgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos a visualizar alguna de las imágenes de la BD de MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imprimamos el primer ejemplo\n",
    "plt.imshow(X[0].reshape(28, 28), cmap='gray')\n",
    "print(\"Label: \" + str(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4NRE88w-DOx"
   },
   "source": [
    "Ahora usamos nuestro clasificador de la distancia euclídea para predecir la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 48479 / 60000\n",
      "Success rate: 80.79833333333333\n"
     ]
    }
   ],
   "source": [
    "# ------ MNIST Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "all_X, all_y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=True)\n",
    "X = all_X[:60000]\n",
    "y = all_y[:60000].astype(int)\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(y)\n",
    "classifEuclid.fit(X, y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, list(y))\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Xn7msweCDk5"
   },
   "source": [
    "## Isolet Dataset (Isolated Letter Speech Recognition)\n",
    "Tratar de predecir ahora esta otra base de datos sobre reconociento de voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "QmefmuvR-33P",
    "outputId": "e79b4b59-4132-4130-e468-1b458c851445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 6843 / 7797\n",
      "Success rate: 87.7645248172374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ------ Isolet Database ------\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=True)\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "classifEuclid = ClassifEuclid(y)\n",
    "classifEuclid.fit(X, y)\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "predict_matrix = classifEuclid.predict(X)\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, y)\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(y))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris, Wine y Cancer Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 139 / 150\n",
      "Success rate: 92.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# --------- Iris database ---------\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "dataset = load_iris()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 129 / 178\n",
      "Success rate: 72.47191011235955\n"
     ]
    }
   ],
   "source": [
    "# --------- Wine database ---------\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "dataset = load_wine()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 507 / 569\n",
      "Success rate: 89.103690685413\n"
     ]
    }
   ],
   "source": [
    "# --------- Cancer database ---------\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "samples = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "classifEuclid = ClassifEuclid(labels)\n",
    "\n",
    "classifEuclid.fit(samples, labels)\n",
    "\n",
    "predict_matrix = classifEuclid.predict(samples)\n",
    "\n",
    "labels_matrix = classifEuclid.pred_label(predict_matrix)\n",
    "\n",
    "correct = classifEuclid.num_aciertos(labels_matrix, labels)\n",
    "\n",
    "print(\"Correct answers:\", correct[0], \"/\", len(labels))\n",
    "print(\"Success rate:\", correct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_kQ7OJd9fqD"
   },
   "source": [
    "Resultados de los tres experimentos:\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   |  139 / 150 | 92.66 |\n",
    "| Wine   | 129/178 | 72.47  |\n",
    "| Cancer | 507/569 | 89.10 |\n",
    "| **MNIST**  | 48479 / 60000 |80.80|\n",
    "| **Isolet** | 6843 / 7797 | 87.76 |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EsqueletoPractica2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
